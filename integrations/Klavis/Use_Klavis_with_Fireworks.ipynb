{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fireworks-ai/cookbook/blob/main/integrations/Klavis/Use_Klavis_with_Fireworks.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Fireworks AI + Klavis AI Integration\n",
        "\n",
        "In this tutorial, we'll explore how to build an AI agent that integrates Fireworks AI's LLM with Klavis MCP Servers:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before we begin, you'll need:\n",
        "\n",
        "- **Fireworks AI API key** - see here [fireworks.ai](https://fireworks.ai/)\n",
        "- **Klavis API key** - see here [klavis.ai](https://klavis.ai/)\n",
        "\n",
        "Make sure to keep these API keys secure and never commit them to version control!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "%pip install -qU fireworks-ai requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"FIREWORKS_API_KEY\"] = \"fw_XXXXXXXXX\"  # Replace with your actual Fireworks API key\n",
        "os.environ[\"KLAVIS_API_KEY\"] = \"XXXXXXXXX\"    # Replace with your actual Klavis API key\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up Klavis API\n",
        "\n",
        "Klavis API is built on REST principles. Check out the [documentation](https://docs.klavis.ai/api-reference/introduction) if you're interested in learning more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import urllib.parse\n",
        "from typing import Dict, Any, Optional, List\n",
        "import webbrowser\n",
        "\n",
        "class KlavisAPI:\n",
        "    \"\"\"API Client for Klavis API.\"\"\"\n",
        "    \n",
        "    def __init__(self, api_key: str, base_url: str = \"https://api.klavis.ai\"):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = base_url\n",
        "        self.headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "    \n",
        "    def _make_request(self, method: str, endpoint: str, **kwargs) -> Dict[str, Any]:\n",
        "        \"\"\"Make HTTP request with error handling.\"\"\"\n",
        "        url = f\"{self.base_url}{endpoint}\"\n",
        "        response = requests.request(method, url, headers=self.headers, **kwargs)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    \n",
        "    def create_mcp_instance(self, server_name: str, user_id: str, platform_name: str) -> Dict[str, str]:\n",
        "        \"\"\"Create MCP server instance.\"\"\"\n",
        "        data = {\n",
        "            \"serverName\": server_name,\n",
        "            \"userId\": user_id,\n",
        "            \"platformName\": platform_name,\n",
        "            \"connectionType\": \"StreamableHttp\"\n",
        "        }\n",
        "        result = self._make_request(\"POST\", \"/mcp-server/instance/create\", json=data)\n",
        "        print(f\"‚úÖ Created {server_name} MCP instance\")\n",
        "        return {\n",
        "            'serverUrl': result['serverUrl'],\n",
        "            'instanceId': result['instanceId']\n",
        "        }\n",
        "    \n",
        "    def list_tools(self, server_url: str) -> Dict[str, Any]:\n",
        "        \"\"\"List all available tools for an MCP server.\"\"\"\n",
        "        params = {\"connection_type\": \"StreamableHttp\"}\n",
        "        encoded_url = urllib.parse.quote(server_url, safe='')\n",
        "        return self._make_request(\"GET\", f\"/mcp-server/list-tools/{encoded_url}\", params=params)\n",
        "    \n",
        "    def _convert_mcp_tools_to_openai_format(self, mcp_tools: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Convert MCP tools format to OpenAI function calling format.\"\"\"\n",
        "        openai_tools = []\n",
        "        \n",
        "        for tool in mcp_tools:\n",
        "            openai_tool = {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": tool.get(\"name\", \"\"),\n",
        "                    \"description\": tool.get(\"description\", \"\"),\n",
        "                    \"parameters\": tool.get(\"inputSchema\", {})\n",
        "                }\n",
        "            }\n",
        "            openai_tools.append(openai_tool)\n",
        "        \n",
        "        return openai_tools\n",
        "    \n",
        "    def call_tool(self, server_url: str, tool_name: str, \n",
        "                  tool_args: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Call tool on MCP server.\"\"\"\n",
        "        data = {\n",
        "            \"serverUrl\": server_url,\n",
        "            \"toolName\": tool_name,\n",
        "            \"toolArgs\": tool_args or {},\n",
        "            \"connectionType\": \"StreamableHttp\"\n",
        "        }\n",
        "        return self._make_request(\"POST\", \"/mcp-server/call-tool\", json=data)\n",
        "    \n",
        "    # Advanced use case if the MCP server requires OAuth authorization\n",
        "    def redirect_to_oauth(self, instance_id: str, server_name: str) -> None:\n",
        "        \"\"\"Open OAuth authorization URL in browser.\"\"\"\n",
        "        oauth_url = f\"{self.base_url}/oauth/{server_name.lower()}/authorize?instance_id={instance_id}\"\n",
        "        print(f\"üîê Opening OAuth authorization for {server_name}, if you are not redirected, please open the following URL in your browser: {oauth_url}\")\n",
        "        webbrowser.open(oauth_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Create AI Agent with MCP Integration\n",
        "\n",
        "Now we'll create an intelligent agent that can use MCP servers through Klavis API. This agent will:\n",
        "\n",
        "1. **Discover Tools**: Automatically find available tools from MCP servers\n",
        "2. **Function Calling**: Use Fireworks AI's function calling capabilities\n",
        "3. **Tool Execution**: Execute tools through Klavis API\n",
        "4. **Smart Responses**: Generate intelligent responses based on tool results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, fireworks_client, klavis_api_client, mcp_server_url):\n",
        "        self.fireworks = fireworks_client\n",
        "        self.klavis = klavis_api_client\n",
        "        self.mcp_server_url = mcp_server_url\n",
        "        self.model = \"accounts/fireworks/models/qwen2p5-72b-instruct\"\n",
        "        print(f\"ü§ñ Agent initialized with model: {self.model}\")\n",
        "    \n",
        "    def process_request(self, user_message):\n",
        "        # 1. Get available tools\n",
        "        mcp_tools = self.klavis.list_tools(self.mcp_server_url)\n",
        "        tools = self.klavis._convert_mcp_tools_to_openai_format(mcp_tools.get('tools', [])) # qwen model support openai format\n",
        "        \n",
        "        # 2. Call LLM with tools\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "        \n",
        "        response = self.fireworks.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "            tools=tools\n",
        "        )\n",
        "        \n",
        "        assistant_message = response.choices[0].message\n",
        "        messages.append(assistant_message)\n",
        "        \n",
        "        # 3. If LLM wants to use tools\n",
        "        if assistant_message.tool_calls:\n",
        "            \n",
        "            # Execute each tool call\n",
        "            for tool_call in assistant_message.tool_calls:\n",
        "                tool_name = tool_call.function.name\n",
        "                tool_args = json.loads(tool_call.function.arguments)\n",
        "                \n",
        "                print(f\"üõ†Ô∏è Calling tool: {tool_name} with args: {tool_args}\")\n",
        "                # Call tool via Klavis API\n",
        "                tool_result = self.klavis.call_tool(\n",
        "                    server_url=self.mcp_server_url,\n",
        "                    tool_name=tool_name,\n",
        "                    tool_args=tool_args\n",
        "                )\n",
        "                \n",
        "                messages.append({\n",
        "                    \"role\": \"tool\",\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"content\": json.dumps(tool_result)\n",
        "                })\n",
        "            \n",
        "            # 4. Get final response from LLM\n",
        "            final_response = self.fireworks.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=messages\n",
        "            )\n",
        "            return final_response.choices[0].message.content\n",
        "        \n",
        "        # If no tools needed, return the assistant message directly\n",
        "        return assistant_message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Case 1: YouTube Video Analysis\n",
        "\n",
        "Let's demonstrate the power of our MCP agent by analyzing a YouTube video. The agent will:\n",
        "\n",
        "1. **Extract Video Information**: Get metadata like title, duration, views, etc.\n",
        "2. **Retrieve Transcript**: Access the full video transcript\n",
        "3. **Generate Summary**: Create a comprehensive summary with timestamps\n",
        "4. **Provide Insights**: Offer key takeaways and structured information\n",
        "\n",
        "Simply provide a YouTube URL and let the agent do the work!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Summary of the Video: \"How This AI Startup Grew by 100x in Just 6 Months | Fireworks AI, Lin Qiao\"\n",
            "\n",
            "**Title:** How This AI Startup Grew by 100x in Just 6 Months | Fireworks AI, Lin Qiao  \n",
            "**Channel:** EO  \n",
            "**Published:** August 20, 2024  \n",
            "**Duration:** 11 minutes and 55 seconds  \n",
            "**Views:** 77,268  \n",
            "**Likes:** 1,650  \n",
            "**Comments:** 51  \n",
            "\n",
            "**Description:**\n",
            "Fireworks AI is one of the fastest-growing AI startups in the industry. Over the past six months, the company has experienced a 100x increase in traffic and successfully closed a Series B funding round led by Sequoia, bringing its valuation to $552 million. Lin Qiao, the founder and CEO, previously served as the Head of PyTorch, shares how her experiences there inspired the creation of Fireworks AI. She discusses the ongoing AI transformation and offers insights into what it takes to excel as a software engineer in this rapidly evolving landscape.\n",
            "\n",
            "**Timestamps:**\n",
            "\n",
            "- **0:00 - 1:30:** Introduction to Fireworks AI and its rapid growth over the past six months, including a 100x increase in traffic and a successful Series B funding round led by Sequoia.\n",
            "- **1:30 - 3:00:** Lin Qiao's background and her role as the Head of PyTorch, highlighting how her experiences there influenced the creation of Fireworks AI.\n",
            "- **3:00 - 4:30:** Overview of the AI industry and the challenges and opportunities it presents, especially for startups.\n",
            "- **4:30 - 6:00:** Detailed insights into the strategies and innovations that drove Fireworks AI's growth, including product development and market positioning.\n",
            "- **6:00 - 7:30:** Discussion on the importance of community and collaboration in the AI space, and how Fireworks AI leveraged these aspects.\n",
            "- **7:30 - 9:00:** Lin Qiao shares her vision for the future of AI and the role Fireworks AI will play in shaping it.\n",
            "- **9:00 - 10:30:** Advice for aspiring software engineers and entrepreneurs looking to succeed in the AI industry.\n",
            "- **10:30 - 11:55:** Conclusion and final thoughts on the journey of Fireworks AI and the broader AI landscape.\n",
            "\n",
            "**Contact Information:**\n",
            "- **Twitter:** @EO__Global\n",
            "- **LinkedIn:** @EO STUDIO\n",
            "- **Instagram:** @eostudio.official\n",
            "\n",
            "**Subtitles:**\n",
            "- Created using [XL8.ai](http://xl8.ai/) machine translation.\n",
            "\n",
            "This video provides valuable insights into the rapid growth of Fireworks AI and the key factors that contributed to its success, making it a must-watch for anyone interested in the AI industry.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from fireworks.client import Fireworks\n",
        "\n",
        "YOUTUBE_VIDEO_URL = \"https://www.youtube.com/watch?v=kPXvf2-C_Hs\" # pick a video you like!\n",
        "\n",
        "# 1. Initialize Fireworks AI client and Klavis API client\n",
        "fireworks_client = Fireworks(api_key=os.getenv(\"FIREWORKS_API_KEY\"))\n",
        "klavis_api_client = KlavisAPI(api_key=os.getenv(\"KLAVIS_API_KEY\"))\n",
        "\n",
        "# 2. Create a YouTube MCP server using Klavis API\n",
        "youtube_mcp_instance = klavis_api_client.create_mcp_instance(\n",
        "    server_name=\"YouTube\",\n",
        "    user_id=\"1234\",\n",
        "    platform_name=\"Klavis\",\n",
        ")\n",
        "\n",
        "# 3. Create an agent with YouTube MCP server\n",
        "agent = Agent(fireworks_client, klavis_api_client, youtube_mcp_instance[\"serverUrl\"])\n",
        "\n",
        "response = agent.process_request(\n",
        "    f\"Summarize this YouTube video with timestamps: {YOUTUBE_VIDEO_URL}\"\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Case 2: Email Automation with Gmail\n",
        "\n",
        "Our second use case demonstrates email automation using Gmail's MCP server. This example shows how to:\n",
        "\n",
        "1. **OAuth Authentication**: Securely connect to Gmail using OAuth\n",
        "2. **Email Composition**: Use AI to craft professional emails\n",
        "3. **Email Sending**: Send emails programmatically through Gmail API\n",
        "4. **Confirmation**: Receive confirmation of successful delivery\n",
        "\n",
        "**Note**: Gmail integration requires OAuth authentication, so you'll need to authorize the application in your browser. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from fireworks.client import Fireworks\n",
        "\n",
        "EMAIL_SUBJECT = \"Hello, World!\"\n",
        "EMAIL_BODY = \"This is a test email.\"\n",
        "EMAIL_RECIPIENT = \"connect@klavis.ai\" # replace with your email\n",
        "\n",
        "# 1. Initialize Fireworks AI client and Klavis API client\n",
        "fireworks_client = Fireworks(api_key=os.getenv(\"FIREWORKS_API_KEY\"))\n",
        "klavis_api_client = KlavisAPI(api_key=os.getenv(\"KLAVIS_API_KEY\"))\n",
        "\n",
        "# 2. Create a Gmail MCP server using Klavis API\n",
        "gmail_mcp_instance = klavis_api_client.create_mcp_instance(\n",
        "    server_name=\"Gmail\",\n",
        "    user_id=\"1234\",\n",
        "    platform_name=\"Klavis\",\n",
        ")\n",
        "\n",
        "# 3. Redirect to Gmail OAuth page\n",
        "klavis_api_client.redirect_to_oauth(gmail_mcp_instance[\"instanceId\"], \"Gmail\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The email has been sent successfully to zihaolin@klavis.ai with the subject \"Hello, World!\" and the body \"This is a test email.\" The email ID is 1977620de59daa96.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 4. Create an agent with Gmail MCP server\n",
        "agent = Agent(fireworks_client, klavis_api_client, gmail_mcp_instance[\"serverUrl\"])\n",
        "\n",
        "response = agent.process_request(\n",
        "    f\"Send an email to {EMAIL_RECIPIENT} with subject {EMAIL_SUBJECT} and body {EMAIL_BODY}\"\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéâ Conclusion\n",
        "\n",
        "Congratulations! You've successfully built AI agents that can interact with any MCP server with Klavis. Here's what we accomplished:\n",
        " \n",
        "### üöÄ Next Steps\n",
        "- **Explore More MCP Servers**: Try other available servers like Slack, Notion, CRM, etc..\n",
        "- **Try Different Fireworks AI Models**: Experiment with various models like Llama, Mixtral, or Deepseek for different use cases\n",
        "- **Build Complex Multi-Server Workflows**: Create sophisticated agents that combine Gmail + Slack + Notion for complete business automation\n",
        "- **Production Deployment**: Scale these patterns for production applications\n",
        "\n",
        "### üîó Useful Resources\n",
        "- [Fireworks AI Documentation](https://docs.fireworks.ai/)\n",
        "- [Klavis AI Documentation](https://docs.klavis.ai/)\n",
        "- [MCP Protocol Specification](https://modelcontextprotocol.io/)\n",
        "\n",
        "**Happy building!** üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
