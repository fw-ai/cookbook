{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "73b0444b",
      "metadata": {
        "id": "73b0444b"
      },
      "source": [
        "# Using Toolhouse for Tool Use on Fireworks.AI infrastructure\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/orliesaurus/fireworks-cookbook/main/learn/function-calling/notebooks_toolhouse_tools/search_and_generate_toolhouse.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "626a645c",
      "metadata": {
        "id": "626a645c"
      },
      "source": [
        "[Toolhouse](https://app.toolhouse.ai/) is a comprehensive infrastructure platform designed for developing, deploying, and managing tool-based capabilities in large language models (LLMs).\n",
        "\n",
        "Toolhouse enables seamless integration of external functionalities‚Äîreferred to as tools‚Äîinto LLM workflows.\n",
        "\n",
        "Key tool capabilities include:\n",
        "- Extracting structured and unstructured data from web or social media sources\n",
        "- Programmatically generating images\n",
        "- Executing code snippets and returning computed outputs\n",
        "\n",
        "This cookbook provides a technical guide on **enhancing LLMs deployed on** [Fireworks.AI](https://fireworks.ai/) **with tool-based extensions**, eliminating the need for manual coding or explicit prompt engineering.\n",
        "\n",
        "In this demonstration, we detail the process of configuring an LLM to generate images based on real-time data inputs.\n",
        "\n",
        "We will leverage Toolhouse with the `firefunction-v2` model, hosted on Fireworks's infrastructure.\n",
        "\n",
        "This model is optimized for high-precision tool utilization, ensuring robust and accurate execution of integrated tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "002c27a7",
      "metadata": {
        "id": "002c27a7"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install the dependencies.\n",
        "We will use the OpenAI SDK which is compatible with Fireworks's API - as long as we set the base_url.\n",
        "\n",
        "We're also installing Toolhouse's Python SDK to access pre-built, pre-hosted tools."
      ],
      "metadata": {
        "id": "M11wAhQR2JLu"
      },
      "id": "M11wAhQR2JLu"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install toolhouse openai"
      ],
      "metadata": {
        "id": "LaMYsh-3580q",
        "collapsed": true
      },
      "id": "LaMYsh-3580q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d237c86c",
      "metadata": {
        "id": "d237c86c"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from toolhouse import Toolhouse"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "458ace84",
      "metadata": {
        "id": "458ace84"
      },
      "source": [
        "To integrate Fireworks and Toolhouse, you'll need to set up two environment variables: `FIREWORKS_API_KEY` and `TOOLHOUSE_API_KEY`. Follow these steps to obtain your API keys:\n",
        "\n",
        "* **Fireworks API Key**: Get your key by visiting the [Fireworks API Console](https://fireworks.ai/account/api-keys).\n",
        "* **Toolhouse API Key**: Sign up for Toolhouse using [this link](https://join.toolhouse.ai) to receive FREE credits. You will receive your API key as part of the onboarding step, and you can always, navigate to the [Toolhouse API Keys page](https://app.toolhouse.ai/settings/api-keys) to create and get an API key.\n",
        "* **Install the X tool**: In your [Toolhouse dashboard](https://app.toolhouse.ai), click Install next to the \"Search X\" tool ([direct link](https://app.toolhouse.ai/store/search_x)).\n",
        "* **Install the Image Generation tool**: In your [Toolhouse dashboard](https://app.toolhouse.ai), click Install next to the \"Image Generation\" tool ([direct link](https://app.toolhouse.ai/store/image_generation_flux)).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up keys in Colab\n",
        "\n",
        "Once you have signe-up and got both API keys, set them as environment variables to start using Fireworks with Toolhouse.\n",
        "\n",
        "To do that click on the Key icon in the left menu on Colab and click **\"Add new secret\".**\n",
        "\n",
        "Create 2 keys and make sure their **name** is spelled like below:\n",
        "```\n",
        "FIREWORKS_API_KEY\n",
        "TOOLHOUSE_API_KEY\n",
        "```\n",
        "\n",
        "Enter the values for each key and switch on the **allow note book access\"**"
      ],
      "metadata": {
        "id": "dEPpWhup3Fva"
      },
      "id": "dEPpWhup3Fva"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Setting up the SDKs\n",
        "\n",
        "Since we've imported the SDKs already, let's initialize them and authenticate ourselves using the API keys we just set.\n",
        "\n",
        "If you want to check again, your API keys should be now in the left sidebar of Google Colab after clicking the key icon."
      ],
      "metadata": {
        "id": "_kblVg3pXlMy"
      },
      "id": "_kblVg3pXlMy"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bf32deff",
      "metadata": {
        "id": "bf32deff"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "client = OpenAI(base_url = \"https://api.fireworks.ai/inference/v1\", api_key=userdata.get(\"FIREWORKS_API_KEY\"))\n",
        "\n",
        "th = Toolhouse(api_key=userdata.get('TOOLHOUSE_API_KEY'), provider=\"openai\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32220c3f",
      "metadata": {
        "id": "32220c3f"
      },
      "source": [
        "We will use the `accounts/fireworks/models/firefunction-v2` model.\n",
        "\n",
        "This model is based on the Mixtral model and was fine-tuned for tool use and function calling:\n",
        "\n",
        "We can test that we can call the model hosted on Fireworks by running the cell below. It should output some info about NYC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8771ddd7",
      "metadata": {
        "id": "8771ddd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4e16e8-0f0c-44e1-a1cd-72d7915a9364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well, the Big Apple, the City That Never Sleeps, New York City, there's just so much to love about this place! The energy is electric, the diversity is unparalleled, and the opportunities are endless. From iconic landmarks like the Statue of Liberty, Central Park, and Times Square, to world-class museums like the Met and MoMA, there's always something new to explore and discover. And let's not forget about the food ‚Äì from classic New York-style pizza and bagels to cutting-edge culinary innovations, your taste buds will never be bored. Plus, with some of the best universities and research institutions in the world, NYC is a hub for learning and innovation. So, why is New York so awesome? Because it's the city where dreams come true, where anything is possible, and where the world comes to live, work, and play!\n"
          ]
        }
      ],
      "source": [
        "MODEL = \"accounts/fireworks/models/firefunction-v2\"\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"tell me about why new york is awesome\"}],\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89ad14fd",
      "metadata": {
        "id": "89ad14fd"
      },
      "source": [
        "Likewise, you can use the `th.get_tools()` function to display all of the Toolhouse tools you have installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d814c0bf",
      "metadata": {
        "id": "d814c0bf"
      },
      "outputs": [],
      "source": [
        "print('TOOLS AVAILABLE:')\n",
        "fireworks_tools = th.get_tools()\n",
        "for tool in th.get_tools():\n",
        "  for tool in fireworks_tools:\n",
        "    tool.pop(\"required\", None)\n",
        "    print(f\"Name: {tool['function']['name']}\")\n",
        "    print(f\"Type: {tool['type']}\")\n",
        "    print(f\"Description: {tool['function']['description']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5b2b413",
      "metadata": {
        "id": "b5b2b413"
      },
      "source": [
        "For this demo, we will be using two tools from Toolhouse's store.\n",
        "- Search X\n",
        "- Image generation\n",
        "\n",
        "The first tool lets you search the X social network and the second tool lets you generate an image from a prompt and returns it to the LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd565fc7",
      "metadata": {
        "id": "cd565fc7"
      },
      "source": [
        "# 3. Configure Tool Calls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09bf2fec",
      "metadata": {
        "id": "09bf2fec"
      },
      "source": [
        "First we'll configure the user prompt to the LLM.\n",
        "This is a basic python list with a dictionary within it that takes `role` and a `content`.\n",
        "\n",
        "We set `role` to `user` because this is a command that we, the user, want the LLM to understand.\n",
        "\n",
        "Doing so will allow us to give a specific command to the LLM. The LLM will look at what tools we have available and attempt to leverage them to achieve the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "4b457ee7",
      "metadata": {
        "id": "4b457ee7"
      },
      "outputs": [],
      "source": [
        "# User message to the LLM\n",
        "messages = [\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"Find the last three messages from the account named @FireworksAI_HQ on X/Twitter and summarize them in one sentence. Make it funny!\",\n",
        "  }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "396cabd1",
      "metadata": {
        "id": "396cabd1"
      },
      "source": [
        "We'll send this message to our LLM hosted on Fireworks.\n",
        "\n",
        "Because we have tools provided by Toolhouse we can skip having to code our own Search X parser.\n",
        "The tools are hosted and maintained by the Toolhouse team and are optimized for LLM usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08148e22",
      "metadata": {
        "id": "08148e22"
      },
      "outputs": [],
      "source": [
        "# Fireworks response with Toolhouse tools\n",
        "response = client.chat.completions.create(\n",
        "  model=MODEL,\n",
        "  messages=messages,\n",
        "  # Passes the tools to the model\n",
        "  tools=fireworks_tools,\n",
        ")\n",
        "\n",
        "print(\"The LLM autonomously decides to use the following tool(s) to achieve its goal of finding data on X/Twitter\")\n",
        "print(\"Tool selected: \", response.choices[0].message.tool_calls[0].function.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f279224f",
      "metadata": {
        "id": "f279224f"
      },
      "source": [
        "As you can see from the output above, the LLM properly identified that we'd like to invoke the 'search_x' tool\n",
        "\n",
        "You can see the arguments it generated by running the code below, it will break iut down by ID, type and function arguments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8505b93d",
      "metadata": {
        "id": "8505b93d"
      },
      "outputs": [],
      "source": [
        "tools_called = response.choices[0].message.tool_calls\n",
        "for tool_called in tools_called:\n",
        "    print(f\"ID: {tool_called.id}\")\n",
        "    print(f\"Type: {tool_called.type}\")\n",
        "    print(f\"Function: {tool_called.function}\")\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e13ddcaf",
      "metadata": {
        "id": "e13ddcaf"
      },
      "source": [
        "# 4. Execute Tool Call"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0a0978f",
      "metadata": {
        "id": "a0a0978f"
      },
      "source": [
        "Now that we learned how the LLM can generate arguments to pass to a function we'll have to **run the function with those arguments**.\n",
        "\n",
        "The tool gets executed via the `run_tools` command, with the parameters that were identified in the previous LLM call.\n",
        "\n",
        "\n",
        "After that we will get the result, and append it to the context, the `messages` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "355f0f50",
      "metadata": {
        "id": "355f0f50"
      },
      "outputs": [],
      "source": [
        "tool_run = th.run_tools(response)\n",
        "messages += tool_run\n",
        "\n",
        "# Here's what the messages variable contains now\n",
        "print(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what our messages list looks like:"
      ],
      "metadata": {
        "id": "aOTqRaFe7xMa"
      },
      "id": "aOTqRaFe7xMa"
    },
    {
      "cell_type": "code",
      "source": [
        "for message in tool_run:\n",
        "  print(f\"Role: {message['role']}\")\n",
        "  if 'tool_calls' in message:\n",
        "    print(f\"Tool Calls: {message['tool_calls']}\")\n",
        "  if 'tool_call_id' in message:\n",
        "    print(f\"Tool Call ID: {message['tool_call_id']}\")\n",
        "    print(f\"Content: {message['content']}\")\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "ZqeSLyYhJRMc"
      },
      "id": "ZqeSLyYhJRMc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "84ceb341",
      "metadata": {
        "id": "84ceb341"
      },
      "source": [
        "We're now going to pass the whole message chain to the LLM. The LLM will generate a proper response based on our initial prompt:\n",
        "\n",
        "```\n",
        "Find the last three messages from the account named @FireworksAI_HQ on X/Twitter and summarize them in one sentence. Make it funny!\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 The Funny Summary"
      ],
      "metadata": {
        "id": "8rJ0agFQ-v6a"
      },
      "id": "8rJ0agFQ-v6a"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "84f24416",
      "metadata": {
        "id": "84f24416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be68834b-a8e9-4db5-8bd0-341db588142a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM RESPONSE: The last three messages from @FireworksAI_HQ on X/Twitter summarize to this funny sentence: \"One day, @FireworksAI_HQ just woke up and decided to rule all complex reasoning benchmarks with its new model, f1. But then it got distracted by all the sweet AI Game Night invites and forgot to conquer the world... yet!\" üòÇ\n"
          ]
        }
      ],
      "source": [
        "messages_filter = [{k: v for k, v in msg.items() if k not in [\"audio\", \"refusal\"]} for msg in messages]\n",
        "summary_response = client.chat.completions.create(\n",
        "  model=MODEL,\n",
        "  messages=messages_filter\n",
        ")\n",
        "\n",
        "print('LLM RESPONSE:', summary_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add this last response - a funny summary of three posts retrieved from X - to the history of messages.\n",
        "\n",
        "To achieve this we're combining two arrays into a new variable called `new_messages`."
      ],
      "metadata": {
        "id": "1sJuKocpNd0_"
      },
      "id": "1sJuKocpNd0_"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "f3b5513b",
      "metadata": {
        "id": "f3b5513b"
      },
      "outputs": [],
      "source": [
        "new_messages = messages_filter + [\n",
        "  {\n",
        "    \"role\": \"assistant\",\n",
        "    \"content\": summary_response.choices[0].message.content,\n",
        "  }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we're going to give a new command to the LLM - generate us an image from this funny caption using the tool provided by Toolhouse.\n",
        "\n",
        "This tool uses Flux - an image model hosted on Fireworks, then hosts it to a storage location on the img.toolhouse.ai subdomain.\n",
        "\n",
        "> This shows you that a tool can be used to perform multiple action at once (image generation and hosting), but it's up to you - the user and creator of tools - how to set up every tool for best agentic use.\n",
        "\n",
        "We've installed this tool in step 1."
      ],
      "metadata": {
        "id": "T9K6hrDkbbIP"
      },
      "id": "T9K6hrDkbbIP"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "generate_image_request = new_messages + [\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"Generate an image from the funny summary\"\n",
        "  }\n",
        "]\n",
        "\n",
        "generate_image_request_filtered = [{k: v for k, v in msg.items() if k not in [\"audio\", \"refusal\"]} for msg in generate_image_request]\n",
        "\n",
        "# Let's ask the LLM to generate the image\n",
        "image_response = client.chat.completions.create(\n",
        "  model=MODEL,\n",
        "  messages=generate_image_request,\n",
        "  tools=fireworks_tools\n",
        ")\n",
        "tool_run = th.run_tools(image_response)"
      ],
      "metadata": {
        "id": "rQtHdIjObpZA"
      },
      "id": "rQtHdIjObpZA",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the LLM generated an image and stored it, we just want it to let the user know that the image is ready and can be viewed.\n",
        "\n",
        "We're going to - yet again - ask the LLM to take the output of the function call and generate a response."
      ],
      "metadata": {
        "id": "-9RI1IWZbX4I"
      },
      "id": "-9RI1IWZbX4I"
    },
    {
      "cell_type": "code",
      "source": [
        "image_messages = generate_image_request + tool_run\n",
        "image_messages_filtered = [{k: v for k, v in msg.items() if k not in [\"audio\", \"refusal\"]} for msg in image_messages]\n",
        "\n",
        "last_response = client.chat.completions.create(\n",
        "  model=MODEL,\n",
        "  messages=image_messages_filtered,\n",
        "  tools=fireworks_tools,\n",
        ")\n",
        "\n",
        "print('LLM RESPONSE:', last_response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "Gjk6rNvfXanT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70804bf7-b1b4-45d7-e19c-58446617511d"
      },
      "id": "Gjk6rNvfXanT",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'user', 'content': 'Find the last three messages from the account named @FireworksAI_HQ on X/Twitter and summarize them in one sentence. Make it funny!'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'id': 'call_059bQb1Ev2JA4CwMyK7PoTPY', 'function': {'arguments': '{\"query\": \"@FireworksAI_HQ\", \"max_results\": 3}', 'name': 'search_x'}, 'type': 'function', 'index': 0}]}, {'role': 'tool', 'tool_call_id': 'call_059bQb1Ev2JA4CwMyK7PoTPY', 'name': 'search_x', 'content': '<tweet>After #AWSreInvent sessions, it‚Äôs time for AI Game Night on Dec 3rd! üéÆ \\n\\nJoin @MongoDB, @arizeai, @FireworksAI_HQ &amp; @HasuraHQ for games, drinks, and networking with tech innovators.\\n\\nDon‚Äôt miss it! RSVP today. üëá\\nhttps://t.co/upX3tWOA7x https://t.co/rDls8EJAKt\\nby @Karissa_Wood_ at 2024-11-19T23:21:01.000Z\\n Conversation ID: 1859014042683126052\\n\\n![mongodb.social/6016sSyqq](https://mongodb.social/6016sSyqq\\n\\nPhoto: ![Image](https://pbs.twimg.com/media/GcyLa5cW0AEl67a.jpg)<tweet>\\n\\n<tweet>Will you be at @awscloud re:Invent 2024 next month?\\n\\nJoin us, @mongodb, @cohere, and @FireworksAI_HQ   on Dec 4 at 1 PM (Wynn Las Vegas, Bollinger room) for a panel on building scalable, high-performance #genAI apps. \\n\\nHear from top AI leaders and learn how to level up your AI stack.\\n\\nDon‚Äôt miss it! #reInvent2024 #Anyscale #AI\\nby @anyscalecompute at 2024-11-19T20:11:57.000Z\\n Conversation ID: 1858966463010533522\\n\\n\\nPhoto: ![Image](https://pbs.twimg.com/media/GcxgF_ZbcAI_i7D.jpg)<tweet>\\n\\n<tweet>üèéÔ∏è f1 - a new complex reasoning model from @FireworksAI_HQ \\n\\nseems like this one slipped under the radar a bit yesterday, I haven\\'t seen a ton of mentions of it\\n\\n> üèéÔ∏è f1 is a new \"Compound AI\" system from Fireworks AI that \"interweaves several different open models at inference time\"\\n\\nit\\'s beating both gpt-4o and Sonnet 3.5 on complex reasoning benchmarks (note: o1-preview is still the reasoning king üëë )\\n\\nthe advantage is that you can give it a complex reasoning task and it will autonomously leverage the built in compound reasoning capabilities with a single prompt, extracting away the complexity of building your own compound system\\n\\nin the video you can see me asking it everyone\\'s favorite reasoning task üçì\\n\\nit breaks down the question first by enumerating the letters, then answers correctly\\nby @daniel_mac8 at 2024-11-19T18:33:19.000Z\\n Conversation ID: 1858941639776956457\\n\\n\\n(Video)[https://pbs.twimg.com/ext_tw_video_thumb/1858941506515533824/pu/img/8Bt7W05G-Ee2lVb9.jpg]\\nSources:\\n [video/mp4](https://video.twimg.com/ext_tw_video/1858941506515533824/pu/vid/avc1/1280x720/AT1O_yX8M3CrxZNk.mp4?tag=14)\\n[video/mp4](https://video.twimg.com/ext_tw_video/1858941506515533824/pu/vid/avc1/640x360/Un-jwHJYiGNnE05g.mp4?tag=14)\\n[video/mp4](https://video.twimg.com/ext_tw_video/1858941506515533824/pu/vid/avc1/1920x1080/4TEGJvNlzb2T5ROp.mp4?tag=14)\\n[application/x-mpegURL](https://video.twimg.com/ext_tw_video/1858941506515533824/pu/pl/vCYM85adEMYwB5Vc.m3u8?tag=14)\\n[video/mp4](https://video.twimg.com/ext_tw_video/1858941506515533824/pu/vid/avc1/480x270/_y3mwsXfuT72796Q.mp4?tag=14)<tweet>\\n\\n<tweet>@RubiksAI @lqiao @FireworksAI_HQ @dzhulgakov Impressive scaling. Intriguing connection to real-time data too.\\nby @SufiyanSIshaq at 2024-11-19T17:14:31.000Z\\n Conversation ID: 1819832483040604370\\n\\n\\n<tweet>\\n\\n<tweet>You can now try f1 by @FireworksAI_HQ in the AI Analyst app: https://t.co/RnwBrDxHTv\\nby @e2b_dev at 2024-11-19T16:05:01.000Z\\n Conversation ID: 1858904318826414561\\n\\n![x.com/tereza_tizkova‚Ä¶](https://twitter.com/tereza_tizkova/status/1858904053041754260\\n<tweet>\\n\\n<tweet>f1 (a new model by @FireworksAI_HQ) beats most popular LLMs across benchmarks\\n\\nf1 is a compound AI model, that is, an LLM-based system with more components, e.g., chaining multiple models, retrievers, or external tools\\n\\nSee how to try f1 for free in the ‚ú¥Ô∏è@e2b_dev AI Analyst app ‚ú¥Ô∏èüëá\\nby @tereza_tizkova at 2024-11-19T16:03:57.000Z\\n Conversation ID: 1858904053041754260\\n\\n\\nPhoto: ![Image](https://pbs.twimg.com/media/Gcwm4caWgAAwKHI.jpg)<tweet>\\n\\n<tweet>@cognitivecompai @huybery @Yuchenj_UW @lmarena_ai @FireworksAI_HQ @NousResearch Paris Hackathons too ü§ó\\n\\nI\\'ll be there for the next 1.5 months haha\\nby @calebfahlgren at 2024-11-19T15:10:14.000Z\\n Conversation ID: 1858727523619885215\\n\\n\\n<tweet>\\n\\n<tweet>After #AWSreInvent sessions, it‚Äôs time for AI Game Night on Dec 3rd! üéÆ \\n\\nJoin @MongoDB, @arizeai, @FireworksAI_HQ &amp; @HasuraHQ for games, drinks, and networking with tech innovators.\\n\\nDon‚Äôt miss it! RSVP today. üëá\\nhttps://t.co/6wtwpEQluN https://t.co/8xS8SEPVB5\\nby @pietrosandonato at 2024-11-19T13:32:38.000Z\\n Conversation ID: 1858865970938278236\\n\\n![mongodb.social/6015soPuW](https://mongodb.social/6015soPuW\\n\\nPhoto: ![Image](https://pbs.twimg.com/media/GcwEwAEXsAAGDYj.jpg)<tweet>\\n\\n<tweet>@sonyatweetybird @FireworksAI_HQ try it out here: https://t.co/yL4EvPFrzN https://t.co/H1Uvzu0ngd\\nby @_akhaliq at 2024-11-19T07:17:08.000Z\\n Conversation ID: 1858614388787474769\\n\\n![huggingface.co/spaces/akhaliq‚Ä¶](https://huggingface.co/spaces/akhaliq/anychat\\n\\nPhoto: ![Image](https://pbs.twimg.com/media/Gcuuy5jXYAAplEe.jpg)<tweet>\\n\\n<tweet>After #AWSreInvent sessions, it‚Äôs time for AI Game Night on Dec 3rd! üéÆ \\n\\nJoin @MongoDB, @arizeai, @FireworksAI_HQ &amp; @HasuraHQ for games, drinks, and networking with tech innovators.\\n\\nDon‚Äôt miss it! RSVP today. üëá\\nhttps://t.co/fcIaTshU64 https://t.co/wzlzAierct\\nby @anujbpanchal at 2024-11-19T07:01:19.000Z\\n Conversation ID: 1858767494418239611\\n\\n![mongodb.social/6017sl9xf](https://mongodb.social/6017sl9xf\\n\\nPhoto: ![Image](https://pbs.twimg.com/media/GcurL4nWEAAUMmC.jpg)<tweet>\\n'}, {'role': 'assistant', 'content': 'The last three messages from @FireworksAI_HQ on X/Twitter summarize to this funny sentence: \"One day, @FireworksAI_HQ just woke up and decided to rule all complex reasoning benchmarks with its new model, f1. But then it got distracted by all the sweet AI Game Night invites and forgot to conquer the world... yet!\" üòÇ'}, {'role': 'user', 'content': 'Generate an image from the funny summary'}, {'content': None, 'refusal': None, 'role': 'assistant', 'audio': None, 'tool_calls': [{'id': 'call_Fb1JuuM8vGUskB7qGWtrg2gT', 'function': {'arguments': '{\"prompt\": \"a photo of a cat, sitting on the couch, looking at the camera with its ruler hat, beside a table with notebooks labeled @FireworksAI_HQ f1. The background is a world map. The cat\\'s face is funny and curious. There is a small AI Game Night invitation on top of the table\", \"width\": \"512\", \"height\": \"512\", \"steps\": \"15\"}', 'name': 'image_generation_flux'}, 'type': 'function', 'index': 0}]}, {'role': 'tool', 'tool_call_id': 'call_Fb1JuuM8vGUskB7qGWtrg2gT', 'name': 'image_generation_flux', 'content': '{\"result\":\"https://img.toolhouse.ai/7E4EnI.jpg\"}'}]\n",
            "LLM RESPONSE: ![](https://img.toolhouse.ai/7E4EnI.jpg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And there you have it, if you have managed to run all the cells in the correct order you should see a message with a valid URL. If you click it you will be able to see the generated image! The image is pretty random and truly depends on what \"funny summary\" we generated in step 4.1"
      ],
      "metadata": {
        "id": "TwDJcIG_cN46"
      },
      "id": "TwDJcIG_cN46"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
