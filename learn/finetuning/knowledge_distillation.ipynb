{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge Distillation with Fireworks AI"
      ],
      "metadata": {
        "id": "U1YlK0wGLGC9"
      },
      "id": "U1YlK0wGLGC9"
    },
    {
      "cell_type": "markdown",
      "id": "0726f87d",
      "metadata": {
        "id": "0726f87d"
      },
      "source": [
        "Transfer knowledge from large teacher models to smaller, low-cost, more efficient student models while preserving performance.\n",
        "\n",
        "Knowledge distillation enables you to create compact models that maintain the reasoning capabilities of larger models. This tutorial demonstrates the complete workflow using GSM8K mathematical reasoning as our example task.\n",
        "\n",
        "| **Technique** | **Teacher Model** | **Student Model** | **Primary Goal** |\n",
        "|---------------|-------------------|-------------------|-------------------------|\n",
        "| **Supervised Fine-Tuning (SFT)** | DeepSeek-V3 (685B) | Qwen2.5-7B | Format Learning & Structure |\n",
        "| **Reinforcement Fine-Tuning (RFT)** | N/A (Self-improvement) | Supervised Fine-Tuned Qwen2.5-7B | Accuracy Optimization |\n",
        "\n",
        "\n",
        "**Qwen2.5-7B (52% accuracy) + DeepSeek-V3 knowledge → Optimized 7B model (70% accuracy, structured format)**\n",
        "\n",
        "\n",
        "## Course Overview\n",
        "\n",
        "This tutorial demonstrates a systematic two-stage knowledge distillation pipeline:\n",
        "\n",
        "**Stage 1 - SFT (Format Learning)**:\n",
        "1. Generate training data with consistent output formatting\n",
        "2. Train student model to internalize structured response patterns\n",
        "3. Demonstrate format learning without explicit instructions\n",
        "\n",
        "**Stage 2 - RFT (Accuracy Improvement)**:\n",
        "\n",
        "4. Build reward system based on answer correctness\n",
        "\n",
        "5. Apply reinforcement learning to improve reasoning within learned format\n",
        "\n",
        "6. Show accuracy gains while maintaining consistent structure\n",
        "\n",
        "**Why This Two-Stage Approach Works**:\n",
        "- **SFT**: Excels at learning structural patterns and making them default behavior\n",
        "- **RFT**: Excels at optimizing content quality through reward-based learning  \n",
        "- **Together**: Create models that are both well-formatted AND more accurate\n",
        "\n",
        "## Chapter 1: Environment Setup\n",
        "\n",
        "**Requirements:**\n",
        "- [Fireworks AI](https://fireworks.ai/) account with API access\n",
        "- Basic familiarity with fine-tuning concepts\n",
        "- Understanding of train/test splits for valid evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d72b047",
      "metadata": {
        "id": "7d72b047"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install --upgrade fireworks-ai\n",
        "\n",
        "# Core imports for the entire course\n",
        "from fireworks import LLM, Dataset\n",
        "import fireworks\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import random\n",
        "from typing import List, Dict, Optional\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "269b3911",
      "metadata": {
        "id": "269b3911"
      },
      "source": [
        "### API Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61b276f8",
      "metadata": {
        "id": "61b276f8"
      },
      "outputs": [],
      "source": [
        "# Get your Fireworks AI API Key at https://app.fireworks.ai/settings/users/api-keys\n",
        "os.environ['FIREWORKS_API_KEY'] = 'your-fireworks-api-key'\n",
        "\n",
        "# Test SDK connection\n",
        "llm = LLM(model=\"llama4-maverick-instruct-basic\", deployment_type=\"serverless\")\n",
        "\n",
        "response = llm.chat.completions.create(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello! Can you help me learn about AI?\"}]\n",
        ")\n",
        "\n",
        "print(\"SDK Connection Test:\")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df48d89",
      "metadata": {
        "id": "2df48d89"
      },
      "source": [
        "**What's Happening Here:**\n",
        "\n",
        "- Fireworks SDK: Simplified interface for model deployment and fine-tuning\n",
        "- Serverless Models: Pre-deployed models you can use immediately\n",
        "- API Key: Authenticates your requests and tracks usage\n",
        "\n",
        "## Chapter 2: Dataset Preparation and Analysis\n",
        "\n",
        "**Why GSM8K?**\n",
        "- **Standard Benchmark**: Widely used for evaluating mathematical reasoning\n",
        "- **Clear Evaluation**: Numerical answers are easy to check for correctness\n",
        "- **Appropriate Difficulty**: Challenging enough to demonstrate knowledge transfer\n",
        "\n",
        "**Why We Need Proper Train/Test Splits**\n",
        "\n",
        "**Critical for Valid Evaluation**: Using the same data for training and testing leads to inflated results that don't reflect real-world performance. GSM8K provides standard splits that enable fair comparison with other research.\n",
        "\n",
        "### Load GSM8K Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1865f873",
      "metadata": {
        "id": "1865f873"
      },
      "outputs": [],
      "source": [
        "# Load both splits\n",
        "splits = {\n",
        "    'train': 'main/train-00000-of-00001.parquet',\n",
        "    'test': 'main/test-00000-of-00001.parquet'\n",
        "}\n",
        "\n",
        "# Load train set\n",
        "df_train = pd.read_parquet(\"hf://datasets/openai/gsm8k/\" + splits[\"train\"])\n",
        "\n",
        "# Load test set\n",
        "df_test = pd.read_parquet(\"hf://datasets/openai/gsm8k/\" + splits[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683dfd6a",
      "metadata": {
        "id": "683dfd6a"
      },
      "source": [
        "```\n",
        "Dataset Statistics:\n",
        "  • Train size: 7473\n",
        "  • Test size: 1319\n",
        "  • Total: 8792\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "084c2788",
      "metadata": {
        "id": "084c2788"
      },
      "source": [
        "**Example GSM8K Problem:**\n",
        "\n",
        "```\n",
        "{\n",
        "    'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
        "    'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72',\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32387c5d",
      "metadata": {
        "id": "32387c5d"
      },
      "source": [
        "**Why This Format Matters**: The `#### 18` format provides the ground truth answer we need for automated evaluation. We'll extract this pattern to check model correctness.\n",
        "\n",
        "**Process Dataset for Training and Evaluation**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37593023",
      "metadata": {
        "id": "37593023"
      },
      "outputs": [],
      "source": [
        "gsm8k_train_problems = []\n",
        "for idx, row in df_train.iterrows():\n",
        "    answer_match = re.search(r'#### (\\d+)', row['answer'])\n",
        "    ground_truth = answer_match.group(1) if answer_match else None\n",
        "\n",
        "    if ground_truth:\n",
        "        gsm8k_train_problems.append({\n",
        "            \"question\": row['question'],\n",
        "            \"ground_truth\": ground_truth,\n",
        "            \"full_solution\": row['answer']\n",
        "        })\n",
        "\n",
        "gsm8k_test_problems = []\n",
        "for idx, row in df_test.iterrows():\n",
        "    answer_match = re.search(r'#### (\\d+)', row['answer'])\n",
        "    ground_truth = answer_match.group(1) if answer_match else None\n",
        "\n",
        "    if ground_truth:\n",
        "        gsm8k_test_problems.append({\n",
        "            \"question\": row['question'],\n",
        "            \"ground_truth\": ground_truth,\n",
        "            \"full_solution\": row['answer']\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db5c8770",
      "metadata": {
        "id": "db5c8770"
      },
      "source": [
        "## Chapter 3: Model Setup\n",
        "\n",
        "### Deploy Your Student Model\n",
        "\n",
        "**Model Selection**: We're using [Qwen2.5-7B](https://fireworks.ai/models/fireworks/qwen2p5-7b) as our student model because:\n",
        "- **Right Size**: Large enough to learn complex patterns, small enough to be efficient\n",
        "- **Strong Base**: Pre-trained on diverse data including mathematical content\n",
        "- **Cost-Effective**: Significantly cheaper to run than larger models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb034e9b",
      "metadata": {
        "id": "cb034e9b"
      },
      "outputs": [],
      "source": [
        "# Deploy the base model for training and inference\n",
        "base_llm = LLM(\n",
        "    model=\"qwen2p5-7b\",\n",
        "    id=\"kd-base-model\",  # Unique identifier\n",
        "    deployment_type=\"on-demand\",  # Scales automatically\n",
        "    min_replica_count=0,\n",
        "    max_replica_count=1\n",
        ")\n",
        "\n",
        "# Apply the deployment configuration\n",
        "base_llm.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f1c4d6",
      "metadata": {
        "id": "75f1c4d6"
      },
      "source": [
        "### Testing Baseline Model Behavior\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72369051",
      "metadata": {
        "id": "72369051"
      },
      "outputs": [],
      "source": [
        "# Test our baseline model on a sample problem\n",
        "sample_question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much does she make every day at the farmers' market?\"\n",
        "\n",
        "baseline_response = base_llm.chat.completions.create(\n",
        "    messages=[{\"role\": \"user\", \"content\": sample_question}],\n",
        "    max_tokens = 10000\n",
        ")\n",
        "\n",
        "baseline_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "906152e6",
      "metadata": {
        "id": "906152e6"
      },
      "source": [
        "**Expected Baseline Behavior**: Unstructured, verbose responses without consistent formatting patterns.\n",
        "\n",
        "**Actual Baseline Model Outputs:**\n",
        "\n",
        "Output 1:\n",
        "\n",
        "```\n",
        "Janet has 16 eggs per day. She eats 3 into breakfast, leaving her with 16-3 = 13 eggs. Out of these, she uses 4 for her muffin recipes, which results in 13-4 = 9 eggs left. Selling each of these leftover eggs at $2, she makes 9*2 = $18 per day at the market.\n",
        "\n",
        "print(9*2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb14538f",
      "metadata": {
        "id": "fb14538f"
      },
      "source": [
        "Output 2:\n",
        "```\n",
        "Janet starts with 16 ducks eggs. Each day, she eats 3 for breakfast and uses 4 for her muffins, which totals 7 eggs.\n",
        "\n",
        "The remainder she sells. So, the remaining eggs are 16 - 7. She sells these at $2 per egg.\n",
        "\n",
        "We can calculate her daily earnings from selling eggs with this simple math. I will write a python code snippet to perform this calculation.\n",
        "```python\n",
        "# Number of eggs laid by ducks daily\n",
        "laying_daily = 16\n",
        "\n",
        "# Number of eggs used by Janet and her friends\n",
        "eggs_for_use = 3 + 4\n",
        "\n",
        "# Number of eggs remaining to sell\n",
        "remaining_eggs = laying_daily - eggs_for_use\n",
        "\n",
        "#_price per fresh duck egg\n",
        "price_per_egg = 2\n",
        "\n",
        "# Daily earnings by selling the remaining eggs\n",
        "daily_cool = remaining_eggs * price_per_egg\n",
        "print(daily_cool)\n",
        "\n",
        "output\n",
        "20\n",
        "\n",
        "Janet sells the remainder eggs at the farmers' market, making \\$20 per day.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "659bf632",
      "metadata": {
        "id": "659bf632"
      },
      "source": [
        "## Chapter 4: Stage 1 - Supervised Fine-Tuning (SFT)\n",
        "\n",
        "### Generate Formatted Training Data with Teacher Model\n",
        "\n",
        "#### Why Use a Teacher Model\n",
        "\n",
        "**The Knowledge Transfer Principle**\n",
        "\n",
        "Rather than learning math reasoning from scratch, we'll have a powerful model (DeepSeek-V3) solve problems step-by-step, then train our small model to mimic those high-quality solutions.\n",
        "\n",
        "**Why [DeepSeek-V3](https://fireworks.ai/models/fireworks/deepseek-v3-0324)**:\n",
        "\n",
        "- **Strong mathematical reasoning** (>90% accuracy on GSM8K)\n",
        "- **Clear step-by-step explanations** that provide good learning examples\n",
        "- **Consistent output format** when given proper instructions\n",
        "- **Cost-effective** for generating training data (no deployment required)\n",
        "- **Available as serverless model on Fireworks AI platform**\n",
        "\n",
        "**Two-Stage Data Strategy**: We'll generate one high-quality dataset from our teacher model and adapt it for both training stages:\n",
        "\n",
        "- **Stage 1 (SFT)**: Use teacher responses as training targets to learn format patterns\n",
        "- **Stage 2 (RFT)**: Use the same problems with ground truth labels for reward-based learning\n",
        "\n",
        "### Defining Our Target Format\n",
        "\n",
        "**Why Structured Output?**\n",
        "- **Consistency**: Every response follows the same pattern\n",
        "- **Parseability**: Easy to extract answers programmatically\n",
        "- **Debugging**: Clear separation of reasoning and results\n",
        "- **Production Ready**: Reliable format for downstream applications\n",
        "- **Unique**: Different from typical model outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ccb9609",
      "metadata": {
        "id": "9ccb9609"
      },
      "source": [
        "```\n",
        "TARGET_FORMAT_EXAMPLE = \"\"\"\n",
        "[WORK]\n",
        "1. Janet's ducks lay 16 eggs per day\n",
        "2. She eats 3 eggs for breakfast  \n",
        "3. She uses 4 eggs for muffins\n",
        "4. Remaining eggs: 16 - 3 - 4 = 9 eggs\n",
        "5. Revenue: 9 eggs × $2/egg = $18\n",
        "[/WORK]\n",
        "\n",
        "[RESULT]\n",
        "18\n",
        "[/RESULT]\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "### Teaching the Teacher Model Our Format\n",
        "\n",
        "**Strategy**: We'll use a system prompt to teach our teacher model (DeepSeek-V3) to use our desired format, then capture those formatted responses as training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ffb0c42",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "7ffb0c42"
      },
      "outputs": [],
      "source": [
        "# System prompt that teaches the format\n",
        "SYSTEM_PROMPT = \"\"\"You are a math tutor. When solving problems, always structure your response in this exact format:\n",
        "\n",
        "[WORK]\n",
        "Show your step-by-step reasoning here. Work through the problem systematically, showing calculations and logic clearly.\n",
        "[/WORK]\n",
        "\n",
        "[RESULT]\n",
        "Put only the final numerical answer here (no units, no extra text)\n",
        "[/RESULT]\n",
        "\n",
        "Follow this format exactly for every math problem.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06452fd7",
      "metadata": {
        "id": "06452fd7"
      },
      "outputs": [],
      "source": [
        "# Test the teacher model with our format instructions\n",
        "sample_question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much does she make every day at the farmers' market?\"\n",
        "\n",
        "messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}, {\"role\": \"user\", \"content\": sample_question}]\n",
        "\n",
        "teacher_llm = LLM(model=\"deepseek-v3\", deployment_type=\"serverless\")\n",
        "\n",
        "teacher_response = teacher_llm.chat.completions.create(\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "teacher_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19902355",
      "metadata": {
        "id": "19902355"
      },
      "source": [
        "**Actual teacher model response:**\n",
        "\n",
        "```\n",
        "[WORK]\n",
        "1. Janet's ducks lay 16 eggs per day.\n",
        "2. She eats 3 eggs for breakfast daily.\n",
        "3. She uses 4 eggs for baking muffins daily.\n",
        "4. Total eggs used or consumed: \\(3 + 4 = 7\\)\n",
        "5. Eggs remaining for sale: \\(16 - 7 = 9\\)\n",
        "6. Price per egg: \\$2\n",
        "7. Daily earnings at the farmers' market: \\(9 \\times 2 = 18\\)\n",
        "[/WORK]\n",
        "\n",
        "[RESULT]\n",
        "18\n",
        "[/RESULT]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caf453d7",
      "metadata": {
        "id": "caf453d7"
      },
      "source": [
        "### Generating High-Quality Training Data\n",
        "\n",
        "**The Process**:\n",
        "1. Take problems from GSM8K training set\n",
        "2. Have teacher model solve them using our format\n",
        "3. Verify teacher got the right answer\n",
        "4. Create training examples from successful solutions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1f3120",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "eb1f3120"
      },
      "outputs": [],
      "source": [
        "def extract_answer_from_result_tags(response: str) -> str:\n",
        "    \"\"\"Extract answer from [RESULT] tags\"\"\"\n",
        "    result_match = re.search(r'\\[RESULT\\](.*?)\\[/RESULT\\]', response, re.DOTALL)\n",
        "    if result_match:\n",
        "        return result_match.group(1).strip()\n",
        "    return None\n",
        "\n",
        "def generate_sft_training_data(train_problems_sample):\n",
        "    \"\"\"Generate training data using teacher model with format instructions\"\"\"\n",
        "\n",
        "    sft_dataset = []\n",
        "    successful_examples = 0\n",
        "\n",
        "    for i, problem in enumerate(train_problems_sample):\n",
        "\n",
        "        # Get teacher response with format instructions\n",
        "        messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}, {\"role\": \"user\", \"content\": problem[\"question\"]}]\n",
        "\n",
        "        teacher_llm = LLM(model=\"deepseek-v3\", deployment_type=\"serverless\")\n",
        "\n",
        "        teacher_response_obj = teacher_llm.chat.completions.create(\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        teacher_response = teacher_response_obj.choices[0].message.content\n",
        "\n",
        "        # Check if teacher got the right answer\n",
        "        teacher_answer = extract_answer_from_result_tags(teacher_response)\n",
        "\n",
        "        # Only include if teacher got the answer right AND used proper format\n",
        "        if teacher_answer == problem[\"ground_truth\"] and \"[WORK]\" in teacher_response and \"[RESULT]\" in teacher_response:\n",
        "            # Don't include system prompt in training data so model learns\n",
        "            # that the format should be followed even when not in system prompt\n",
        "            training_example = {\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"user\", \"content\": problem[\"question\"]},\n",
        "                    {\"role\": \"assistant\", \"content\": teacher_response}\n",
        "                ]\n",
        "            }\n",
        "            sft_dataset.append(training_example)\n",
        "            successful_examples += 1\n",
        "\n",
        "    return sft_dataset, successful_examples\n",
        "\n",
        "random.seed(42)\n",
        "sampled_problems = random.sample(gsm8k_train_problems, 6000)\n",
        "\n",
        "# Generate SFT training data\n",
        "sft_training_data, successful_count = generate_sft_training_data(sampled_problems)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f661d2b7",
      "metadata": {
        "id": "f661d2b7"
      },
      "source": [
        "**Actual result:**\n",
        "\n",
        "```\n",
        "Generated 5700 high-quality training examples\n",
        "Teacher success rate: 5700/6000 examples\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccd1a15f",
      "metadata": {
        "id": "ccd1a15f"
      },
      "source": [
        "**Why Use a Teacher Model When We Already Have Answers?**\n",
        "\n",
        "**You might be wondering**: \"Wait, the GSM8K dataset already has the correct answers. Why do we need a teacher model to generate new ones?\"\n",
        "\n",
        "**Great question!** This tutorial uses GSM8K because it provides a controlled environment where we can verify our teacher model's accuracy. But in real-world applications, you typically **don't have the correct answers** for your specific domain.\n",
        "\n",
        "**The Knowledge Distillation Advantage**\n",
        "\n",
        "The Pattern: In production, you have:\n",
        "\n",
        "- Questions/Inputs: Your domain-specific problems\n",
        "- No Perfect Answers: No ground truth responses\n",
        "- Solution: Use a powerful teacher model to create accurate high-quality training data\n",
        "\n",
        "## Real-World Knowledge Distillation Use Cases\n",
        "\n",
        "### Common Scenarios Where You Need Teacher Models\n",
        "\n",
        "**1. Legal Document Analysis**\n",
        "- **Challenge**: No ground truth for contract clause interpretation\n",
        "- **Teacher Solution**: Use teacher models to generate expert-level legal analyses\n",
        "\n",
        "**2. Code Review Automation**\n",
        "- **Challenge**: No perfect code review comments for your codebase  \n",
        "- **Teacher Solution**: Use teacher models to generate code review insights\n",
        "\n",
        "**4. Customer Support Chatbot**\n",
        "- **Challenge**: No ideal responses for company-specific questions\n",
        "- **Teacher Solution**: Use teacher models for customer service responses\n",
        "\n",
        "**6. Content Moderation**  \n",
        "- **Challenge**: No labeled decisions for edge-case content\n",
        "- **Teacher Solution**: Use teacher models to generate moderation reasoning and decisions\n",
        "\n",
        "### Popular Open Source Teacher Models\n",
        "\n",
        "- **[Kimi K2](https://app.fireworks.ai/models/fireworks/kimi-k2-instruct)**: Great general purpose model, especially for agentic use cases.\n",
        "- **[Qwen3 Coder 480B](https://app.fireworks.ai/models/fireworks/qwen3-coder-480b-a35b-instruct)**: Strong coding model, especially for one-off coding tasks.\n",
        "- **[Qwen3 235B (instruct)](https://app.fireworks.ai/models/fireworks/qwen3-235b-a22b-instruct-2507)**: Good general purpose model. Has strong world knowledge for tasks like classification.\n",
        "- **[Qwen3 235B (thinking)](https://app.fireworks.ai/models/fireworks/qwen3-235b-a22b-thinking-2507)**: Good reasoning model for agentic tasks and tasks that require multi-step planning.\n",
        "- **[Open AI GPT OSS 120B](https://app.fireworks.ai/models/fireworks/gpt-oss-120b)**: OpenAI's open-weight model, with strong reasoning and tool use capabilities. Runs efficiently on single 80GB GPU and achieves near-parity with o4-mini on core reasoning benchmarks.\n",
        "- **[DeepSeek V3](https://app.fireworks.ai/models/fireworks/deepseek-v3-0324)**: Powerful MoE model with 671B parameters (37B active) that rivals GPT-4o and Claude 3.5 Sonnet. Strong performance in math, coding, and reasoning tasks.\n",
        "- **[DeepSeek R1](https://app.fireworks.ai/models/fireworks/deepseek-r1-0528)**: Open-source reasoning model that rivals OpenAI o1. Trained using pure reinforcement learning. Shows explicit chain-of-thought reasoning process and excels at complex mathematical and logical problems.\n",
        "\n",
        "### Uploading Training Data to Fireworks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d363e0b5",
      "metadata": {
        "id": "d363e0b5"
      },
      "outputs": [],
      "source": [
        "# Save to file first\n",
        "dataset_filename = \"kd_sft_dataset.jsonl\"\n",
        "with open(dataset_filename, 'w') as f:\n",
        "    for example in sft_training_data:\n",
        "        f.write(json.dumps(example) + '\\n')\n",
        "\n",
        "# Upload to Fireworks\n",
        "dataset = Dataset.from_file(dataset_filename)\n",
        "dataset.sync()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "887329ab",
      "metadata": {
        "id": "887329ab"
      },
      "source": [
        "### SFT Training Configuration\n",
        "\n",
        "**Supervised Fine-Tuning Job**:\n",
        "  - **Model**: `Qwen2.5 7B`\n",
        "  - **Dataset**: dataset (Your uploaded dataset)  \n",
        "  - **Epochs**: 5-8 (format learning needs repetition)\n",
        "  - **Learning Rate**: 1e-5\n",
        "\n",
        "**Critical Parameters for Format Learning**:\n",
        "- **Higher Learning Rate**: Needed to override existing response patterns\n",
        "- **More Epochs**: Format internalization requires repetition\n",
        "- **Larger Model**: 3B+ has capacity to learn complex structural patterns\n",
        "- **No System Prompts in Training**: Teaches default behavior, not instruction-following\n",
        "\n",
        "### Running the SFT Training Job\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2424f5ed",
      "metadata": {
        "id": "2424f5ed"
      },
      "outputs": [],
      "source": [
        "# Create fine-tuning job\n",
        "job = base_llm.create_supervised_fine_tuning_job(\n",
        "    display_name=\"kd-sft-job\",\n",
        "    dataset_or_id=dataset.id,\n",
        "    epochs=3,\n",
        "    learning_rate=1e-5\n",
        ")\n",
        "\n",
        "job.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f60c3687",
      "metadata": {
        "id": "f60c3687"
      },
      "source": [
        "### Deploying the Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1c330f4",
      "metadata": {
        "id": "a1c330f4"
      },
      "outputs": [],
      "source": [
        "sft_llm = LLM(\n",
        "    model=job.output_model,\n",
        "    deployment_type=\"on-demand\",\n",
        "    id=\"kd-sft-model\",\n",
        "    min_replica_count=0,\n",
        "    max_replica_count=1\n",
        ")\n",
        "sft_llm.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03c2c5ab",
      "metadata": {
        "id": "03c2c5ab"
      },
      "source": [
        "## Chapter 5: Evaluating SFT Results\n",
        "\n",
        "### Testing Format Learning Success\n",
        "\n",
        "**The Critical Test**: Can our fine-tuned model use the target format WITHOUT being explicitly told to do so?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a1e864",
      "metadata": {
        "id": "81a1e864"
      },
      "outputs": [],
      "source": [
        "sample_question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much does she make every day at the farmers' market?\"\n",
        "\n",
        "sft_llm_response = sft_llm.chat.completions.create(\n",
        "    messages=[{\"role\": \"user\", \"content\": sample_question}]\n",
        ")\n",
        "\n",
        "sft_llm_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd16497f",
      "metadata": {
        "id": "fd16497f"
      },
      "source": [
        "**Actual output:**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e820ce95",
      "metadata": {
        "id": "e820ce95"
      },
      "source": [
        "```\n",
        "Okay, let's see. Janet's ducks lay 16 eggs each day. She eats 3 eggs every morning for breakfast. Then she bakes muffins and uses 4 eggs for that. The rest she sells at the market for $2 each. So, I need to calculate how much she makes daily from the sales.\n",
        "\n",
        "First, I'll find out how many eggs she has after eating and baking. So, total eggs laid per day is 16. She eats 3, so 16 - 3 = 13 eggs left. Then she uses 4 eggs for muffins, so 13 - 4 = 9 eggs remaining.\n",
        "\n",
        "Now, she sells these 9 eggs at $2 each. So, 9 eggs * $2 = $18. That should be her daily earnings from the market.\n",
        "\n",
        "[WORK]\n",
        "1. Total eggs laid per day: 16\n",
        "2. Eggs eaten for breakfast: 3\n",
        "3. Eggs used for muffins: 4\n",
        "4. Eggs remaining after eating and baking: 16 - 3 - 4 = 9\n",
        "5. Price per egg: $2\n",
        "6. Total earnings from farmers' market: 9 * 2 = 18\n",
        "[/WORK]\n",
        "\n",
        "[RESULT]\n",
        "18\n",
        "[/RESULT]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bebb9578",
      "metadata": {
        "id": "bebb9578"
      },
      "source": [
        "**SUCCESS! SFT taught the model to automatically use the target format!**\n",
        "\n",
        "This demonstrates how SFT can make structural patterns the model's default behavior.\n",
        "\n",
        "If your format learning is incomplete, consider:\n",
        "- More training examples (aim for 1000+)\n",
        "- Higher learning rate (try 1e-4)  \n",
        "- More epochs (try 5-8)\n",
        "- Verify training data format consistency\n",
        "\n",
        "Now that we have consistent, structured responses, we can focus purely on improving the *quality* of the content within that structure. This is where Stage 2 (RFT) shines - optimizing for correctness while maintaining our learned formatting.\n",
        "\n",
        "### Understanding SFT's Strengths and Limitations\n",
        "\n",
        "Strengths demonstrated\n",
        "\n",
        "- Consistent output formatting\n",
        "- No system prompts needed\n",
        "- Internalized behavior patterns\n",
        "\n",
        "Limitations to address\n",
        "\n",
        "- Accuracy may not improve dramatically\n",
        "- Only mimics teacher, doesn't generalize\n",
        "- No feedback loop for corrections\n",
        "\n",
        "## Chapter 6: Stage 2 - Reinforcement Fine-Tuning (RFT)\n",
        "\n",
        "Now that our model consistently uses the `[WORK]` and `[RESULT]` format **automatically** (without being told), we can apply RFT to improve the accuracy of answers within that structure.\n",
        "\n",
        "### Why Add Reinforcement Learning\n",
        "\n",
        "**Beyond Imitation**: While SFT teaches the model to mimic the teacher's style, RFT optimizes for **correctness**. The model learns to:\n",
        "- Prefer reasoning paths that lead to correct answers\n",
        "- Self-correct when making mistakes  \n",
        "- Develop confidence in its mathematical reasoning\n",
        "\n",
        "**How RFT Works**: Instead of just copying teacher responses, RFT gives the model a reward (+1) for correct answers and penalty (0) for wrong answers, encouraging the model to find its own path to the right solution.\n",
        "\n",
        "**RFT Advantages with SFT Foundation**:\n",
        "- Easy reward calculation from `[RESULT]` tags  \n",
        "- Maintains learned formatting while optimizing correctness\n",
        "\n",
        "### Creating the RFT Dataset\n",
        "\n",
        "**Strategy**: Reuse the same problems our teacher model solved correctly during SFT generation, but format them for reinforcement learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f2efa6f",
      "metadata": {
        "id": "2f2efa6f"
      },
      "outputs": [],
      "source": [
        "def create_rft_dataset_from_sft(sft_training_data, max_samples=1000):\n",
        "    \"\"\"\n",
        "    Create RFT dataset by extracting problems from existing SFT dataset\n",
        "    \"\"\"\n",
        "\n",
        "    rft_data = []\n",
        "    problems_processed = 0\n",
        "\n",
        "    for sft_example in sft_training_data:\n",
        "        if problems_processed >= max_samples:\n",
        "            break\n",
        "\n",
        "        user_question = None\n",
        "        teacher_response = None\n",
        "\n",
        "        # Extract user question and teacher response from messages\n",
        "        for message in sft_example[\"messages\"]:\n",
        "            if message[\"role\"] == \"user\":\n",
        "                user_question = message[\"content\"]\n",
        "            elif message[\"role\"] == \"assistant\":\n",
        "                teacher_response = message[\"content\"]\n",
        "\n",
        "        if user_question and teacher_response:\n",
        "            # Extract ground truth from teacher's [RESULT] tags\n",
        "            ground_truth = extract_answer_from_result_tags(teacher_response)\n",
        "\n",
        "            if ground_truth:\n",
        "                rft_example = {\n",
        "                    \"messages\": [\n",
        "                        {\"role\": \"user\", \"content\": user_question}\n",
        "                    ],\n",
        "                    \"ground_truth\": ground_truth\n",
        "                }\n",
        "                rft_data.append(rft_example)\n",
        "                problems_processed += 1\n",
        "    return rft_data\n",
        "\n",
        "# Create RFT dataset from our existing SFT dataset\n",
        "rft_training_data = create_rft_dataset_from_sft(sft_training_data, max_samples=1000)\n",
        "\n",
        "# Save to file\n",
        "dataset_filename = \"kd_rft_dataset-1.jsonl\"\n",
        "with open(dataset_filename, 'w') as f:\n",
        "    for example in rft_training_data:\n",
        "        f.write(json.dumps(example) + '\\n')\n",
        "\n",
        "# Upload dataset to Fireworks\n",
        "dataset = Dataset.from_file(\"kd_rft_dataset-1.jsonl\")\n",
        "dataset.sync()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e781885",
      "metadata": {
        "id": "6e781885"
      },
      "source": [
        "This is what an RFT training data point looks like:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8ceba48",
      "metadata": {
        "id": "d8ceba48"
      },
      "source": [
        "```\n",
        "{\"messages\": [{\"role\": \"user\", \"content\": \"There are enough provisions in a castle to feed 300 people for 90 days. After 30 days, 100 people leave the castle. How many more days are left until all the food runs out?\"}], \"ground_truth\": \"90\"}\n",
        "```\n",
        "\n",
        "### Understanding Reward Kit and Evaluators\n",
        "\n",
        "**What is Reward Kit?**\n",
        "\n",
        "[Reward Kit](https://docs.fireworks.ai/evaluators/documentation_home) is Fireworks AI's framework for creating custom evaluation functions for reinforcement learning. Think of it as the \"grading system\" that tells the model whether its answers are right or wrong.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3888457",
      "metadata": {
        "id": "a3888457"
      },
      "outputs": [],
      "source": [
        "# Create a comprehensive evaluator for math problems\n",
        "\n",
        "rft_evaluator_code = '''\n",
        "import re\n",
        "from reward_kit import reward_function\n",
        "from reward_kit.models import EvaluateResult\n",
        "\n",
        "@reward_function\n",
        "def evaluate(messages: list[dict], **kwargs) -> EvaluateResult:\n",
        "    \"\"\"\n",
        "    RFT Evaluator: Compare model answer with ground truth\n",
        "    Optimized for [WORK]/[RESULT] format from SFT stage\n",
        "    \"\"\"\n",
        "\n",
        "    # Get ground truth from dataset\n",
        "    ground_truth_answer = kwargs.get('ground_truth')\n",
        "    if not ground_truth_answer:\n",
        "        return EvaluateResult(score=0.0, reason=\"No ground truth found in dataset\")\n",
        "\n",
        "    # Get the model's generated response (last message)\n",
        "    model_response = messages[-1][\"content\"]\n",
        "\n",
        "    # Extract model's answer using multiple methods\n",
        "    model_answer = extract_model_answer(model_response)\n",
        "\n",
        "    if not model_answer:\n",
        "        return EvaluateResult(score=0.0, reason=\"No answer extracted from model response\")\n",
        "\n",
        "    # Clean and compare answers\n",
        "    ground_truth_clean = clean_answer(ground_truth_answer)\n",
        "    model_answer_clean = clean_answer(model_answer)\n",
        "\n",
        "    if model_answer_clean == ground_truth_clean:\n",
        "        return EvaluateResult(score=1.0, reason=f\"Correct: {model_answer_clean}\")\n",
        "    else:\n",
        "        return EvaluateResult(score=0.0, reason=f\"Wrong: {model_answer_clean} vs {ground_truth_clean}\")\n",
        "\n",
        "def extract_model_answer(text: str) -> str:\n",
        "    \"\"\"Extract answer from model response, prioritizing our learned format\"\"\"\n",
        "\n",
        "    # Method 1: [RESULT] tags (primary method for our SFT model)\n",
        "    result_match = re.search(r'\\\\[RESULT\\\\](.*?)\\\\[/RESULT\\\\]', text, re.DOTALL)\n",
        "    if result_match:\n",
        "        return result_match.group(1).strip()\n",
        "\n",
        "    # Method 2: \\\\boxed{} format (fallback)\n",
        "    boxed_match = re.search(r'\\\\\\\\boxed\\\\{([^}]+)\\\\}', text)\n",
        "    if boxed_match:\n",
        "        return boxed_match.group(1).strip()\n",
        "\n",
        "    # Method 3: Last significant number in text\n",
        "    numbers = re.findall(r'\\\\b(\\\\d+(?:,\\\\d{3})*(?:\\\\.\\\\d+)?)\\\\b', text)\n",
        "    if numbers:\n",
        "        significant_numbers = [n for n in numbers if float(n.replace(',', '')) >= 1]\n",
        "        if significant_numbers:\n",
        "            return significant_numbers[-1]\n",
        "\n",
        "    return None\n",
        "\n",
        "def clean_answer(answer_str: str) -> str:\n",
        "    \"\"\"Clean and normalize answer\"\"\"\n",
        "    if not answer_str:\n",
        "        return \"\"\n",
        "\n",
        "    # Remove whitespace, commas, dollar signs\n",
        "    cleaned = re.sub(r'[,$\\\\s]', '', str(answer_str).strip())\n",
        "\n",
        "    # Convert to int if whole number\n",
        "    try:\n",
        "        if '.' in cleaned:\n",
        "            float_val = float(cleaned)\n",
        "            if float_val.is_integer():\n",
        "                return str(int(float_val))\n",
        "            else:\n",
        "                return str(float_val)\n",
        "        else:\n",
        "            return str(int(cleaned))\n",
        "    except ValueError:\n",
        "        return cleaned\n",
        "'''\n",
        "\n",
        "# Save the evaluator\n",
        "rft_evaluator_filename = \"kd-rft-evaluator.py\"\n",
        "with open(rft_evaluator_filename, 'w') as f:\n",
        "    f.write(rft_evaluator_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12ec802b",
      "metadata": {
        "id": "12ec802b"
      },
      "source": [
        "### Setting Up RFT Training (Manual Dashboard Configuration)\n",
        "\n",
        "Due to the complexity of reinforcement learning setup, we'll use the Fireworks dashboard for the final configuration steps.\n",
        "\n",
        "#### Step 1: Upload the RFT Evaluator\n",
        "\n",
        "1. **Navigate to Evaluators**\n",
        "   - Go to [https://app.fireworks.ai/dashboard/evaluations](https://app.fireworks.ai/dashboard/evaluations)\n",
        "\n",
        "2. **Create New Evaluator**\n",
        "   - Click **\"Create Evaluator\"**\n",
        "   - **Evaluator Name**: `kd-rft-evaluator`\n",
        "\n",
        "3. **Configure Dataset**\n",
        "   - Select **\"Select an existing dataset\"**\n",
        "   - Choose the `kd-rft-dataset` you uploaded earlier\n",
        "\n",
        "4. **Add Evaluator Code**\n",
        "   - Choose **\"Start from scratch\"**\n",
        "   - Click **\"Next\"**\n",
        "   - In the code editor, delete any existing code\n",
        "   - Copy and paste the complete code from `kd-rft-evaluator.py`\n",
        "\n",
        "5. **Save Evaluator**\n",
        "   - Click **\"Save Evaluator\"**\n",
        "   - Your evaluator is now ready for RFT training\n",
        "\n",
        "#### Step 2: Create RFT Training Job\n",
        "\n",
        "1. **Navigate to Fine-Tuning**\n",
        "   - Go to the **Fine-Tuning** tab in the dashboard\n",
        "   - Click **\"Fine-Tune a Model\"**\n",
        "   - Select **\"Reinforcement\"** tab\n",
        "\n",
        "2. **Configure Training Job**\n",
        "   \n",
        "   **Model Selection:**\n",
        "   - Select your SFT-trained model\n",
        "   - Use `job.output_model` from your SFT job to obtain SFT model name (e.g., `accounts/your-account/models/kd-sft-model`)\n",
        "   \n",
        "   **Dataset:**\n",
        "   - Select `kd-rft-dataset` from the dropdown\n",
        "   \n",
        "   **Evaluator:**\n",
        "   - Select `kd-rft-evaluator` (the one you just created)\n",
        "   \n",
        "   **Training Settings:**\n",
        "   - **Rollout Settings**: Leave as default values\n",
        "   - **Model Output Name**:\n",
        "     - Option 1: Leave blank for auto-generated name\n",
        "     - Option 2: Enter custom name (e.g., `kd-rft-model`)\n",
        "   - **Other Hyperparameters**: Leave as defaults\n",
        "\n",
        "3. **Launch Training**\n",
        "   - Review your configuration\n",
        "   - Click **\"Create Job\"**\n",
        "   - **Important**: Note the output model name for evaluation later\n",
        "\n",
        "4. **Monitoring**\n",
        "- Track progress in the dashboard's [Fine Tuning section](https://app.fireworks.ai/dashboard/fine-tuning).\n",
        "- Once the job status is `Completed`, you can deploy your model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125a068e",
      "metadata": {
        "id": "125a068e"
      },
      "source": [
        "### Deploying the Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cffde0b6",
      "metadata": {
        "id": "cffde0b6"
      },
      "outputs": [],
      "source": [
        "rft_llm = LLM(\n",
        "    model=\"<rft-model-output-name>\", # Replace <rft-model-output-name> with the model ID from your completed fine-tuning job\n",
        "    deployment_type=\"on-demand\",\n",
        "    id=\"kd-rft-model\",\n",
        "    min_replica_count=0,\n",
        "    max_replica_count=1\n",
        ")\n",
        "rft_llm.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3304868",
      "metadata": {
        "id": "e3304868"
      },
      "source": [
        "## Chapter 7: Evaluate Complete Knowledge Distillation Pipeline\n",
        "\n",
        "Now that we've completed our knowledge distillation pipeline, it's time to evaluate our results. But first, we need robust evaluation tools that can handle the complexity of comparing different models fairly.\n",
        "\n",
        "**Why We Need Sophisticated Evaluation Tools**\n",
        "\n",
        "The Challenge: We now have models that may respond in different formats:\n",
        "\n",
        "- Baseline model: Natural language, inconsistent formatting\n",
        "- RFT model: Structured [WORK]/[RESULT] format\n",
        "\n",
        "**The Problem**: Simple string matching won't work because:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9ddaa8b",
      "metadata": {
        "id": "e9ddaa8b"
      },
      "source": [
        "```\n",
        "# These are all the same answer but look different:\n",
        "response_1 = \"The answer is 42 dollars\"\n",
        "response_2 = \"[RESULT]\\n42\\n[/RESULT]\"  \n",
        "response_3 = \"Therefore, the total is $42.00\"\n",
        "response_4 = \"\\\\boxed{42}\"\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b677c0",
      "metadata": {
        "id": "91b677c0"
      },
      "source": [
        "We need evaluation tools that can:\n",
        "\n",
        "- Extract answers from any response format\n",
        "- Normalize numbers (handle commas, decimals, currency)\n",
        "- Track multiple metrics (accuracy, extraction success)\n",
        "\n",
        "**Building Our Evaluation System**\n",
        "\n",
        "Let's build two essential functions that will power our model comparisons:\n",
        "\n",
        "**Answer Extraction Engine**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac912220",
      "metadata": {
        "id": "ac912220"
      },
      "outputs": [],
      "source": [
        "def extract_answer(text: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Answer extraction that tries multiple methods\n",
        "    \"\"\"\n",
        "    # Method 0: [RESULT] tags (primary method for our SFT model)\n",
        "    result_match = re.search(r'\\[RESULT\\](.*?)\\[/RESULT\\]', text, re.DOTALL)\n",
        "    if result_match:\n",
        "        answer = result_match.group(1).strip()\n",
        "        number = extract_number_from_text(answer)\n",
        "        if number:\n",
        "            return number\n",
        "\n",
        "    # Method 1: <answer> tags\n",
        "    answer_tag_match = re.search(r'<answer>\\s*(.*?)\\s*</answer>', text, re.IGNORECASE | re.DOTALL)\n",
        "    if answer_tag_match:\n",
        "        answer = answer_tag_match.group(1).strip()\n",
        "        number = extract_number_from_text(answer)\n",
        "        if number:\n",
        "            return number\n",
        "\n",
        "    # Method 2: \\\\boxed{} format\n",
        "    boxed_match = re.search(r'\\\\boxed\\{([^}]+)\\}', text)\n",
        "    if boxed_match:\n",
        "        number = extract_number_from_text(boxed_match.group(1))\n",
        "        if number:\n",
        "            return number\n",
        "\n",
        "    # Method 3: Last number in the entire text\n",
        "    all_numbers = re.findall(r'\\b(\\d+(?:,\\d{3})*(?:\\.\\d+)?)\\b', text)\n",
        "    if all_numbers:\n",
        "        # Filter out small numbers that might be step numbers\n",
        "        significant_numbers = [n for n in all_numbers if float(n.replace(',', '')) >= 1]\n",
        "        if significant_numbers:\n",
        "            return clean_number(significant_numbers[-1])\n",
        "\n",
        "    # Method 4: \"Therefore\" or conclusion patterns\n",
        "    conclusion_patterns = [\n",
        "        r'[Tt]herefore,?\\s+.*?(\\d+(?:,\\d{3})*(?:\\.\\d+)?)',\n",
        "        r'[Ss]o,?\\s+.*?(\\d+(?:,\\d{3})*(?:\\.\\d+)?)',\n",
        "        r'[Tt]hus,?\\s+.*?(\\d+(?:,\\d{3})*(?:\\.\\d+)?)',\n",
        "        r'[Ii]n total,?\\s+.*?(\\d+(?:,\\d{3})*(?:\\.\\d+)?)',\n",
        "        r'[Aa]ltogether,?\\s+.*?(\\d+(?:,\\d{3})*(?:\\.\\d+)?)',\n",
        "    ]\n",
        "\n",
        "    for pattern in conclusion_patterns:\n",
        "        matches = re.findall(pattern, text)\n",
        "        if matches:\n",
        "            return clean_number(matches[-1])  # Take the last match\n",
        "\n",
        "    # Method 5: \"The answer is\" patterns\n",
        "    answer_is_patterns = [\n",
        "        r'[Tt]he answer is\\s+(\\d+(?:,\\d{3})*(?:\\.\\d+)?)',\n",
        "        r'[Aa]nswer:\\s*(\\d+(?:,\\d{3})*(?:\\.\\d+)?)',\n",
        "        r'[Ff]inal answer:\\s*(\\d+(?:,\\d{3})*(?:\\.\\d+)?)',\n",
        "    ]\n",
        "\n",
        "    for pattern in answer_is_patterns:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            return clean_number(match.group(1))\n",
        "\n",
        "    # Method 6: Numbers at the end of sentences\n",
        "    sentences = text.split('.')\n",
        "    for sentence in reversed(sentences[-3:]):  # Check last 3 sentences\n",
        "        numbers = re.findall(r'\\b(\\d+(?:,\\d{3})*(?:\\.\\d+)?)\\b', sentence)\n",
        "        if numbers:\n",
        "            return clean_number(numbers[-1])\n",
        "\n",
        "    return None\n",
        "\n",
        "def extract_number_from_text(text: str) -> Optional[str]:\n",
        "    \"\"\"Extract the main number from a piece of text\"\"\"\n",
        "    # Look for numbers, prioritizing larger ones\n",
        "    numbers = re.findall(r'\\b(\\d+(?:,\\d{3})*(?:\\.\\d+)?)\\b', text)\n",
        "    if numbers:\n",
        "        return clean_number(numbers[-1])  # Take the last/most significant number\n",
        "    return None\n",
        "\n",
        "def clean_number(number_str: str) -> str:\n",
        "    \"\"\"Clean and normalize number string\"\"\"\n",
        "    # Remove commas and extra whitespace\n",
        "    cleaned = number_str.replace(',', '').strip()\n",
        "\n",
        "    # Convert to int if it's a whole number\n",
        "    try:\n",
        "        if '.' in cleaned:\n",
        "            float_val = float(cleaned)\n",
        "            if float_val.is_integer():\n",
        "                return str(int(float_val))\n",
        "            else:\n",
        "                return str(float_val)\n",
        "        else:\n",
        "            return str(int(cleaned))\n",
        "    except ValueError:\n",
        "        return cleaned\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c51f14b8",
      "metadata": {
        "id": "c51f14b8"
      },
      "source": [
        "**Evaluation System**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4c55566",
      "metadata": {
        "id": "f4c55566"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(MODEL, deployment_id, problems):\n",
        "    \"\"\"Evaluate model\"\"\"\n",
        "\n",
        "    results = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    extraction_failures = 0\n",
        "\n",
        "    for i in range(0, len(problems)):\n",
        "      problem = problems[i]\n",
        "\n",
        "      # Get model response\n",
        "      llm = LLM(\n",
        "        model=MODEL,\n",
        "        deployment_type=\"on-demand\",\n",
        "        id=deployment_id  # The deployment ID that already exists\n",
        "      )\n",
        "\n",
        "      response = llm.chat.completions.create(\n",
        "          messages=[{\"role\": \"user\", \"content\": problem[\"question\"]}]\n",
        "      )\n",
        "      model_response = response.choices[0].message.content\n",
        "      model_answer = extract_answer(model_response)  # Use answer extraction\n",
        "      ground_truth = problem[\"ground_truth\"]\n",
        "\n",
        "      # Track extraction failures\n",
        "      if model_answer is None:\n",
        "          extraction_failures += 1\n",
        "\n",
        "      # Check correctness (only if we extracted something)\n",
        "      is_correct = model_answer == ground_truth if model_answer else False\n",
        "      if is_correct:\n",
        "          correct += 1\n",
        "      total += 1\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c533b61",
      "metadata": {
        "id": "4c533b61"
      },
      "source": [
        "### Test Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cddf766",
      "metadata": {
        "id": "2cddf766"
      },
      "outputs": [],
      "source": [
        "base_accuracy = evaluate_model(\n",
        "    \"qwen2p5-7b\",\n",
        "    \"kd-base-model\",\n",
        "    gsm8k_test_problems\n",
        ")\n",
        "\n",
        "rft_accuracy = evaluate_model(\n",
        "    \"<rft-model-output-name>\", # Replace <rft-model-output-name> with the model ID from your completed fine-tuning job\n",
        "    \"kd_rft_model\",\n",
        "    gsm8k_test_problems\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbba9add",
      "metadata": {
        "id": "fbba9add"
      },
      "source": [
        "### Actual Results Analysis\n",
        "\n",
        "```\n",
        "ACCURACY PROGRESSION:\n",
        "Base Model:  52%\n",
        "→ RFT:       70% (+18pp)\n",
        "Total Gain:  +18 percentage point improvement\n",
        "\n",
        "FORMAT COMPLIANCE:\n",
        "SFT Model:  ~95% use [WORK]/[RESULT] format automatically  \n",
        "RFT Model:  ~95% maintain format + higher accuracy\n",
        "```\n",
        "\n",
        "## Course Summary and Key Takeaways\n",
        "\n",
        "### What We Demonstrated\n",
        "\n",
        "**1. SFT for Internalized Format Learning**:\n",
        "- **Training Strategy**: Include format examples without system prompts in training data\n",
        "- **Testing Strategy**: No system prompts needed - format is internalized  \n",
        "- **Result**: Model automatically uses `[WORK]/[RESULT]` structure as default behavior\n",
        "- **Key Insight**: SFT teaches \"how to respond\" by making patterns the model's natural behavior\n",
        "\n",
        "**2. RFT for Accuracy Improvement**:\n",
        "- **Foundation**: Builds on SFT model\n",
        "- **Optimization**: Reward-based learning improves content quality\n",
        "- **Result**: Significantly improves reasoning accuracy\n",
        "- **Key Insight**: RFT optimizes \"what to respond with\"\n",
        "\n",
        "**3. Two-Stage Pipeline Synergy**:\n",
        "- **Stage 1 (SFT)**: Establishes reliable, consistent response structure\n",
        "- **Stage 2 (RFT)**: Optimizes content quality within that structure\n",
        "- **Combined Result**: Models that are both well-formatted AND accurate\n",
        "\n",
        "### Practical Applications\n",
        "\n",
        "This knowledge distillation approach is valuable for:\n",
        "\n",
        "- **API Integrations**: Reliable output parsing + improved accuracy\n",
        "- **Structured Reasoning Tasks**: Clear thinking process + better results  \n",
        "- **Production Pipelines**: Consistent format + higher quality content\n",
        "- **Evaluation Systems**: Easy answer extraction + improved performance\n",
        "- **Cost Optimization**: Small models with large model capabilities\n",
        "\n",
        "### Expected Resources\n",
        "\n",
        "- **Cost**: ~Costs apply for API calls, deployments and training jobs\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This tutorial demonstrated how to systematically apply knowledge distillation using [Fireworks AI](https://app.fireworks.ai/account/home) to create models that combine the structural reliability of supervised learning with the performance optimization of reinforcement learning.\n",
        "\n",
        "**Key Success Factors**:\n",
        "1. **Clear separation of concerns**: SFT for structure, RFT for accuracy\n",
        "2. **Consistent evaluation methodology**: Test without system prompts to measure true learning\n",
        "3. **Building on foundations**: RFT builds on SFT rather than starting from scratch\n",
        "4. **Quality training data**: High teacher model accuracy and format consistency\n",
        "\n",
        "The result is a compact, efficient model that maintains the reasoning capabilities and output structure of much larger models, making it suitable for production deployment at significantly lower cost and latency.\n",
        "\n",
        "**Next Steps**: Apply this methodology to your own domain-specific tasks by:\n",
        "1. Defining appropriate outputs for your use case\n",
        "2. Generating high-quality teacher demonstrations\n",
        "3. Fine tuning\n",
        "4. Evaluating performance improvements\n",
        "\n",
        "This systematic approach to knowledge distillation enables you to create specialized, efficient models that retain the capabilities of their larger teachers while being practical for real-world deployment.\n",
        "\n",
        "Questions or feedback? Reach out to us on [Discord](https://discord.gg/fireworks-ai)."
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}