{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# NVIDIA Nemotron Nano 2 VL on Fireworks AI\n",
    "\n",
    "This notebook demonstrates how to use NVIDIA Nemotron Nano 2 VL, a powerful 12B multimodal reasoning model for document intelligence and product catalog cleansing deployed on Fireworks AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toc",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to NVIDIA Nemotron Nano 2 VL](#1-introduction-to-nvidia-nemotron-nano-2-vl)\n",
    "2. [Setting Up Deployment on Fireworks AI](#2-setting-up-deployment-on-fireworks-ai)\n",
    "3. [Performance and Speed Metrics](#3-performance-and-speed-metrics)\n",
    "4. [Use Cases](#4-use-cases)\n",
    "   - [Document Intelligence](#41-document-intelligence)\n",
    "   - [Product Catalog Cleansing](#42-product-catalog-cleansing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## 1. Introduction to NVIDIA Nemotron Nano 2 VL\n",
    "\n",
    "### Overview\n",
    "\n",
    "NVIDIA Nemotron Nano 2 VL is the strongest open 12B multimodal reasoning model for video understanding and document intelligence. Built on a hybrid transformer-Mamba architecture, it combines the best of both worlds:\n",
    "\n",
    "- **Accuracy on par with transformer-only models**\n",
    "- **Limited memory and compute usage from Mamba architecture**\n",
    "- **Higher token throughput and lower latency**\n",
    "\n",
    "### Key Features\n",
    "\n",
    "#### Highest Accuracy\n",
    "- Trained with NVIDIA curated high-quality synthetic data\n",
    "- Best-in-class accuracy for:\n",
    "  - Character recognition (OCR)\n",
    "  - Chart reasoning\n",
    "  - Image understanding\n",
    "  - Video understanding\n",
    "  - Document intelligence\n",
    "- **73.2 average score** vs 64.2 with current top VL model on benchmarks including MMMU, MathVista, AI2D, OCRBench, OCRBench-v2, OCR-Reasoning, ChartQA, DocVQA, and Video-MME\n",
    "\n",
    "#### Highest Efficiency\n",
    "- **Up to 10x higher throughput** compared to Llama Nemotron Nano VL\n",
    "- Efficient Video Sampling (EVS) for processing longer videos\n",
    "- Lower total cost of inference\n",
    "\n",
    "\n",
    "### Primary Use Cases\n",
    "\n",
    "1. **AI Assistant with Document Intelligence**\n",
    "   - Customer service (dashboards, screenshots, docs)\n",
    "   - IT, finance, insurance, healthcare forms\n",
    "\n",
    "2. **Content Ingestion**\n",
    "   - Product catalog cleansing\n",
    "   - Dense captioning of images/videos\n",
    "\n",
    "3. **Multi-modal Applications**\n",
    "   - RAG systems with complex documents, figures, graphs, etc\n",
    "   - Agentic apps and services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "## 2. Setting up on demand deployment on Fireworks AI\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before getting started, you'll need:\n",
    "- A Fireworks AI account ([sign up here](https://fireworks.ai))\n",
    "- API key from Fireworks AI dashboard\n",
    "- Python 3.8 or higher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_packages",
   "metadata": {},
   "outputs": [],
   "source": "!./setup.sh"
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "Set up your Fireworks AI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FIREWORKS_API_KEY = os.getenv('FIREWORKS_API_KEY')\n",
    "\n",
    "if not FIREWORKS_API_KEY:\n",
    "    raise ValueError(\"Please set FIREWORKS_API_KEY environment variable\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create on-demand deployment for NVIDIA Nemotron Nano 2 VL\n",
    "\n",
    "Creating an [on-demand deployment](https://fireworks.ai/docs/getting-started/ondemand-quickstart#on-demand-quickstart) for proper testing and benchmarks"
   ],
   "id": "5bd2cb1fbfc9f2e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Update to NVIDIA Nemotron Nano 2 VL when available\n",
    "! firectl create deployment accounts/fireworks/models/qwen2-vl-72b-instruct --min-replica-count 1 --max-replica-count 1 --accelerator-type NVIDIA_H100_80GB"
   ],
   "id": "9f0bf131f13bf17f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "! firectl-admin get deployment <DEPLOYMENT-ID>",
   "id": "c00cb25fb1d4c315"
  },
  {
   "cell_type": "markdown",
   "id": "helper_functions",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "Utility functions for encoding images and making API calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Encode an image file to base64 string.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        Base64 encoded string of the image\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def encode_image_url(image_url):\n",
    "    \"\"\"\n",
    "    Download and encode an image from a URL.\n",
    "    \n",
    "    Args:\n",
    "        image_url: URL of the image\n",
    "        \n",
    "    Returns:\n",
    "        Base64 encoded string of the image\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    response = requests.get(image_url)\n",
    "    return base64.b64encode(response.content).decode('utf-8')\n",
    "\n",
    "\n",
    "def analyze_image(image_source, prompt, is_url=False, max_tokens=1000):\n",
    "    \"\"\"\n",
    "    Analyze an image using the VLM model.\n",
    "    \n",
    "    Args:\n",
    "        image_source: Path to image file or URL\n",
    "        prompt: Text prompt for the model\n",
    "        is_url: Whether image_source is a URL\n",
    "        max_tokens: Maximum tokens in response\n",
    "        \n",
    "    Returns:\n",
    "        Model response text\n",
    "    \"\"\"\n",
    "    # Encode image\n",
    "    if is_url:\n",
    "        image_b64 = encode_image_url(image_source)\n",
    "    else:\n",
    "        image_b64 = encode_image_to_base64(image_source)\n",
    "    \n",
    "    # Make API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{image_b64}\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }],\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def analyze_multiple_images(image_sources, prompt, are_urls=False, max_tokens=1500):\n",
    "    \"\"\"\n",
    "    Analyze multiple images using the VLM model.\n",
    "    \n",
    "    Args:\n",
    "        image_sources: List of image paths or URLs\n",
    "        prompt: Text prompt for the model\n",
    "        are_urls: Whether image_sources contains URLs\n",
    "        max_tokens: Maximum tokens in response\n",
    "        \n",
    "    Returns:\n",
    "        Model response text\n",
    "    \"\"\"\n",
    "    content = [{\"type\": \"text\", \"text\": prompt}]\n",
    "    \n",
    "    # Add all images\n",
    "    for image_source in image_sources:\n",
    "        if are_urls:\n",
    "            image_b64 = encode_image_url(image_source)\n",
    "        else:\n",
    "            image_b64 = encode_image_to_base64(image_source)\n",
    "        \n",
    "        content.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{image_b64}\"\n",
    "            },\n",
    "        })\n",
    "    \n",
    "    # Make API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[{\"role\": \"user\", \"content\": content}],\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "print(\"Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic_example",
   "metadata": {},
   "source": [
    "### Basic Usage Example\n",
    "\n",
    "Quick example to verify the setup works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with a URL image\n",
    "test_image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "\n",
    "result = analyze_image(\n",
    "    image_source=test_image_url,\n",
    "    prompt=\"Describe this image in detail.\",\n",
    "    is_url=True\n",
    ")\n",
    "\n",
    "print(\"Model Response:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "## 3. Performance and Speed Metrics\n",
    "\n",
    "### Benchmarking Setup\n",
    "\n",
    "Let's measure the performance characteristics of the model on Fireworks AI."
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "## TODO: Add / clone llm_bench and run benchmarks vs other VL models",
   "id": "9e0aead567c89946",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "run_benchmark",
   "metadata": {},
   "source": [
    "### Run Performance Benchmark"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## TODO",
   "id": "b054748eb4a1dcd6"
  },
  {
   "cell_type": "markdown",
   "id": "expected_performance",
   "metadata": {},
   "source": [
    "### Expected Performance with Nemotron Nano 2 VL\n",
    "\n",
    "Based on NVIDIA's specifications, Nemotron Nano 2 VL offers:\n",
    "\n",
    "## TODO: update based on above\n",
    "- **Up to 10x higher throughput** compared to Llama Nemotron Nano VL\n",
    "- **Efficient Video Sampling (EVS)** for processing longer videos\n",
    "- **128k context length** support\n",
    "- **Low latency inference** thanks to the hybrid Mamba architecture\n",
    "\n",
    "**Note:** Actual performance metrics will be updated once the model is available on Fireworks AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## 4. Use Cases\n",
    "\n",
    "### 4.1 Document Intelligence\n",
    "\n",
    "Nemotron Nano 2 VL excels at understanding complex documents including:\n",
    "- Forms and invoices\n",
    "- Charts and graphs\n",
    "- Screenshots and dashboards\n",
    "- Healthcare and insurance documents\n",
    "- Financial reports\n",
    "\n",
    "Let's explore document intelligence capabilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc_ocr",
   "metadata": {},
   "source": [
    "#### OCR and Text Extraction\n",
    "\n",
    "Extract text from documents with high accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ocr_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extract text from a document image\n",
    "# Replace with your document image URL or path\n",
    "document_image = \"https://example.com/sample-invoice.jpg\"  # TODO: Add real example\n",
    "\n",
    "ocr_prompt = \"\"\"\n",
    "Extract all text from this document. Organize the output in a structured format.\n",
    "Maintain the original layout and hierarchy where possible.\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment when you have a document image:\n",
    "# result = analyze_image(document_image, ocr_prompt, is_url=True)\n",
    "# print(result)\n",
    "\n",
    "print(\"OCR example ready. Add a document image URL to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc_chart",
   "metadata": {},
   "source": [
    "#### Chart and Graph Analysis\n",
    "\n",
    "Understanding complex charts and extracting insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chart_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Analyze a chart or graph\n",
    "chart_prompt = \"\"\"\n",
    "Analyze this chart and provide:\n",
    "1. The type of chart/visualization\n",
    "2. Key data points and trends\n",
    "3. Main insights or conclusions\n",
    "4. Any notable patterns or anomalies\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment when you have a chart image:\n",
    "# chart_image = \"path/to/chart.png\"\n",
    "# result = analyze_image(chart_image, chart_prompt)\n",
    "# print(result)\n",
    "\n",
    "print(\"Chart analysis example ready. Add a chart image to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc_form",
   "metadata": {},
   "source": [
    "#### Form Understanding and Data Extraction\n",
    "\n",
    "Extract structured data from forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "form_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example: Extract structured data from a form\n",
    "form_prompt = \"\"\"\n",
    "Extract all information from this form and return it as a JSON object.\n",
    "Include field names as keys and the corresponding values.\n",
    "If a field is empty, mark it as null.\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment when you have a form image:\n",
    "# form_image = \"path/to/form.png\"\n",
    "# result = analyze_image(form_image, form_prompt, max_tokens=2000)\n",
    "# \n",
    "# # Parse JSON response\n",
    "# try:\n",
    "#     form_data = json.loads(result)\n",
    "#     print(\"Extracted Form Data:\")\n",
    "#     print(json.dumps(form_data, indent=2))\n",
    "# except json.JSONDecodeError:\n",
    "#     print(\"Response:\", result)\n",
    "\n",
    "print(\"Form extraction example ready. Add a form image to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4_2",
   "metadata": {},
   "source": [
    "### 4.2 Product Catalog Cleansing\n",
    "\n",
    "Use Nemotron Nano 2 VL to clean and enrich product catalog data by:\n",
    "- Extracting product attributes from images\n",
    "- Generating accurate descriptions\n",
    "- Identifying missing or incorrect information\n",
    "- Categorizing products automatically\n",
    "- Quality checking product listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catalog_attributes",
   "metadata": {},
   "source": [
    "#### Product Attribute Extraction\n",
    "\n",
    "Extract detailed attributes from product images:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## TODO add pydantic class and example",
   "id": "709813f4d2eee40b"
  },
  {
   "cell_type": "markdown",
   "id": "catalog_description",
   "metadata": {},
   "source": [
    "#### Automated Product Description Generation\n",
    "\n",
    "Generate SEO-friendly product descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "id": "description_generation",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": "## TODO add pydantic class and example",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to use NVIDIA Nemotron Nano 2 VL on Fireworks AI for:\n",
    "\n",
    "1. **Document Intelligence**: OCR, chart analysis, form extraction, and multi-page document understanding\n",
    "2. **Product Catalog Cleansing**: Attribute extraction, description generation, quality checks, and batch processing\n",
    "\n",
    "### Key Advantages of Nemotron Nano 2 VL:\n",
    "\n",
    "- **Best-in-class accuracy** for OCR, charts, and document understanding (73.2 avg benchmark score)\n",
    "- **10x higher throughput** compared to previous models ## TODO update with actual benchmarks\n",
    "- **128k context length** for processing long documents and videos\n",
    "- **Hybrid transformer-Mamba architecture** for efficiency\n",
    "- **Open weights and permissive license** for customization\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Add your own document and product images to test the examples\n",
    "2. Integrate the model into your production pipelines\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [VLM on Fireworks AI Documentation](https://fireworks.ai/docs/guides/querying-vision-language-models#querying-vision-language-models)\n",
    "- [Model on Hugging Face](https://huggingface.co) (# TODO add actual link)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b268a7f80d0b153e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
