{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# NVIDIA Nemotron Nano 2 VL on Fireworks AI\n",
    "\n",
    "This notebook demonstrates how to use NVIDIA Nemotron Nano 2 VL, a powerful 12B multimodal reasoning model for document intelligence and product catalog cleansing deployed on Fireworks AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toc",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. Introduction to NVIDIA Nemotron Nano 2 VL\n",
    "2. Setting Up Deployment on Fireworks AI\n",
    "3. Using NVIDIA Nemotron Nano 2 VL for Document Intelligence and OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## 1. Introduction to NVIDIA Nemotron Nano 2 VL\n",
    "\n",
    "### Overview\n",
    "\n",
    "NVIDIA Nemotron Nano 2 VL is an open 12B multimodal reasoning model for document intelligence and image analysis. Built on a hybrid transformer-Mamba architecture, it combines the best of both worlds:\n",
    "\n",
    "- **Accuracy on par with transformer-only models**\n",
    "- **Limited memory and compute usage from Mamba architecture**\n",
    "- **Higher token throughput and lower latency**\n",
    "\n",
    "### Key Features\n",
    "\n",
    "#### High Accuracy\n",
    "- Trained with NVIDIA curated high-quality synthetic data\n",
    "- Best-in-class accuracy for:\n",
    "  - Character recognition (OCR)\n",
    "  - Chart reasoning\n",
    "  - Image understanding\n",
    "  - Video understanding\n",
    "  - Document intelligence\n",
    "- **73.2 average score** vs 64.2 with current top VL model on benchmarks including MMMU, MathVista, AI2D, OCRBench, OCRBench-v2, OCR-Reasoning, ChartQA, DocVQA, and Video-MME\n",
    "\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "1. **Document Intelligence**\n",
    "   - IT, finance, insurance, healthcare forms\n",
    "\n",
    "2. **Content Ingestion**\n",
    "   - Product catalog cleansing\n",
    "   - Dense captioning of images/videos\n",
    "\n",
    "3. **Multi-modal Applications**\n",
    "   - RAG systems with complex documents, figures, graphs, etc\n",
    "   - Agentic apps and services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "## 2. Setting up on demand deployment on Fireworks AI\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before getting started, you'll need:\n",
    "- A Fireworks AI account ([sign up here](https://fireworks.ai))\n",
    "- API key from Fireworks AI dashboard ([get one here](https://app.fireworks.ai/settings/users/api-keys))\n",
    "- Python 3.8 or higher"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Installation\n",
    "\n",
    "Install the required packages:"
   ],
   "id": "install"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T03:48:37.013634Z",
     "start_time": "2025-10-28T03:48:36.805787Z"
    }
   },
   "cell_type": "code",
   "source": "! uv pip install -r ../requirements.txt",
   "id": "install_packages",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2mUsing Python 3.12.10 environment at: /Users/robertobarroso/Desktop/repos/cookbook/learn/vlm/.venv\u001B[0m\r\n",
      "\u001B[2mAudited \u001B[1m6 packages\u001B[0m \u001B[2min 54ms\u001B[0m\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "Set up your Fireworks AI API key:"
   ]
  },
  {
   "cell_type": "code",
   "id": "env_setup",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T03:48:39.350480Z",
     "start_time": "2025-10-28T03:48:38.343079Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "from datasets import load_dataset, disable_progress_bars\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import ast\n",
    "import re\n",
    "from typing import List, Dict, Any, Optional, Callable\n",
    "from enum import Enum\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from typing import Union\n",
    "from datetime import datetime\n",
    "\n",
    "disable_progress_bars()\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FIREWORKS_API_KEY = os.getenv('FIREWORKS_API_KEY')\n",
    "\n",
    "if not FIREWORKS_API_KEY:\n",
    "    raise ValueError(\"Please set FIREWORKS_API_KEY environment variable\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create on-demand deployment for NVIDIA Nemotron Nano 2 VL\n",
    "\n",
    "Creating an [on-demand deployment](https://fireworks.ai/docs/getting-started/ondemand-quickstart#on-demand-quickstart) for proper testing and benchmarks"
   ],
   "id": "5bd2cb1fbfc9f2e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "! firectl signin",
   "id": "f0dd89984de6140e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "! firectl create deployment -a <YOUR-ACCOUNT-ID> accounts/fireworks/models/nemotron-nano-v2-12b-vl --accelerator-type NVIDIA_H100_80GB",
   "id": "5ffaf039c03031eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T03:57:09.482297Z",
     "start_time": "2025-10-28T03:57:09.476996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_TOKENS = 10000\n",
    "TEMPERATURE = 0.0\n",
    "\n",
    "# Update both account id and model id based on your deployment\n",
    "ACCOUNT_ID = \"<YOUR-ACCOUNT-ID-HERE>\"\n",
    "DEPLOYMENT_ID = \"<YOUR-DEPLOYMENT-ID-HERE>\"\n",
    "MODEL_NAME = f\"accounts/fireworks/models/nemotron-nano-v2-12b-vl#accounts/{ACCOUNT_ID}/deployments/{DEPLOYMENT_ID}\""
   ],
   "id": "94f1ee9a87b767e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "helper_functions",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "Utility functions for encoding images and making API calls:"
   ]
  },
  {
   "cell_type": "code",
   "id": "helpers",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T03:57:10.946511Z",
     "start_time": "2025-10-28T03:57:10.920065Z"
    }
   },
   "source": [
    "client = OpenAI(\n",
    "    api_key=FIREWORKS_API_KEY or os.getenv(\"FIREWORKS_API_KEY\"),\n",
    "    base_url=\"https://api.fireworks.ai/inference/v1\",\n",
    ")\n",
    "\n",
    "def encode_image_to_base64(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Encode an image file to base64 string.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "\n",
    "    Returns:\n",
    "        Base64 encoded string of the image\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def encode_pil_image_to_base64(pil_image: Image.Image) -> str:\n",
    "    \"\"\"\n",
    "    Encode a PIL Image to base64 string.\n",
    "\n",
    "    Args:\n",
    "        pil_image: PIL Image object\n",
    "\n",
    "    Returns:\n",
    "        Base64 encoded string of the image\n",
    "    \"\"\"\n",
    "    if pil_image.mode not in ('RGB', 'L'):\n",
    "        pil_image = pil_image.convert('RGB')\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    pil_image.save(buffer, format='JPEG')\n",
    "    buffer.seek(0)\n",
    "\n",
    "    return base64.b64encode(buffer.read()).decode('utf-8')\n",
    "\n",
    "def encode_image_url(image_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Download and encode an image from a URL.\n",
    "\n",
    "    Args:\n",
    "        image_url: URL of the image\n",
    "\n",
    "    Returns:\n",
    "        Base64 encoded string of the image\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "    }\n",
    "    response = requests.get(image_url, headers=headers, timeout=30)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    try:\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "\n",
    "        if image.mode not in ('RGB', 'L'):\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "        buffer = BytesIO()\n",
    "        image.save(buffer, format='JPEG')\n",
    "        buffer.seek(0)\n",
    "\n",
    "        return base64.b64encode(buffer.read()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to process image from URL: {str(e)}\")\n",
    "\n",
    "\n",
    "def analyze_image(\n",
    "        image_source: Union[str, Image.Image],\n",
    "        prompt: str,\n",
    "        structured_schema=None,\n",
    "        is_url: bool = False,\n",
    "        max_tokens: int = MAX_TOKENS,\n",
    "        temperature: float = TEMPERATURE\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze an image using the VLM model.\n",
    "\n",
    "    Args:\n",
    "        image_source: Path to image file, URL, or PIL Image object\n",
    "        prompt: Text prompt for the model\n",
    "        structured_schema: Structured schema for the response based on Pydantic class\n",
    "        is_url: Whether image_source is a URL (ignored if PIL Image provided)\n",
    "        max_tokens: Maximum tokens in response\n",
    "\n",
    "    Returns:\n",
    "        Model response (parsed object if structured_schema provided, else string)\n",
    "    \"\"\"\n",
    "    # Determine image type and encode appropriately\n",
    "    if isinstance(image_source, Image.Image):\n",
    "        image_b64 = encode_pil_image_to_base64(image_source)\n",
    "    elif is_url:\n",
    "        image_b64 = encode_image_url(image_source)\n",
    "    else:\n",
    "        image_b64 = encode_image_to_base64(image_source)\n",
    "\n",
    "    # Build message structure\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_b64}\"}\n",
    "            },\n",
    "        ],\n",
    "    }]\n",
    "\n",
    "    # Call appropriate API method based on structured output requirement\n",
    "    if structured_schema:\n",
    "        response = client.chat.completions.parse(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            response_format=structured_schema,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.parsed\n",
    "    else:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "basic_example",
   "metadata": {},
   "source": [
    "### Basic Usage Example\n",
    "\n",
    "Quick example to verify the setup works:"
   ]
  },
  {
   "cell_type": "code",
   "id": "test_example",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T03:57:14.052042Z",
     "start_time": "2025-10-28T03:57:11.798199Z"
    }
   },
   "source": [
    "# Example with a URL image\n",
    "test_image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "\n",
    "result = analyze_image(\n",
    "    image_source=test_image_url,\n",
    "    prompt=\"Describe this image in a 2-3 sentences.\",\n",
    "    is_url=True\n",
    ")\n",
    "\n",
    "print(\"Model Response:\\n\")\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "\n",
      "The image depicts a wooden boardwalk stretching through a lush, green field, surrounded by tall grasses and shrubs. The sky above is a clear blue, dotted with wispy clouds, suggesting a calm, sunny day. The boardwalk, appearing weathered and well-trodden, invites exploration into the serene, natural landscape.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## 3. Use Cases: Document Intelligence\n",
    "\n",
    "Nemotron Nano 2 VL excels at understanding complex documents including:\n",
    "- Forms and invoices (see snippets below for examples)\n",
    "- Screenshots and dashboards\n",
    "- Healthcare and insurance documents\n",
    "- Financial reports\n",
    "\n",
    "Let's explore document intelligence capabilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc_ocr",
   "metadata": {},
   "source": [
    "#### OCR and Text Extraction\n",
    "\n",
    "Extract text from invoices with high accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "id": "ocr_example",
   "metadata": {},
   "source": [
    "IMAGE_SAMPLE_SIZE = 20\n",
    "\n",
    "def extract_invoice_data(sample: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extract relevant invoice fields from a dataset sample.\n",
    "\n",
    "    Args:\n",
    "        sample: Raw sample from the HuggingFace dataset\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with extracted fields, or None if parsing fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_data = json.loads(sample['parsed_data'])\n",
    "        structured_json = ast.literal_eval(parsed_data['json'])\n",
    "        header = structured_json.get('header', {})\n",
    "\n",
    "        return {\n",
    "            'image': sample['image'],\n",
    "            'invoice_date': header.get('invoice_date'),\n",
    "            'invoice_no': header.get('invoice_no'),\n",
    "            'items': structured_json.get('items', []),\n",
    "            'summary': structured_json.get('summary', {})\n",
    "        }\n",
    "    except (json.JSONDecodeError, KeyError, TypeError, ValueError, SyntaxError) as e:\n",
    "        print(f\"Warning: Failed to parse sample {sample.get('id', 'unknown')}: {type(e).__name__}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_dataset_from_hf(dataset_name: str, func_extract: Callable, n_samples: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load invoice samples from HuggingFace dataset and convert to DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dataset_name: Name of the HuggingFace dataset\n",
    "        n_samples: Number of samples to load\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns: image, invoice_date, invoice_no, items, summary\n",
    "    \"\"\"\n",
    "    print(f\"Loading {n_samples} image samples...\")\n",
    "\n",
    "    # Load dataset in streaming mode\n",
    "    ds = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "\n",
    "    samples = []\n",
    "    for i, sample in enumerate(ds):\n",
    "        if i >= n_samples:\n",
    "            break\n",
    "\n",
    "        extracted = func_extract(sample)\n",
    "        if extracted:\n",
    "            samples.append(extracted)\n",
    "\n",
    "    if not samples:\n",
    "        raise ValueError(f\"Failed to parse any samples. Check error messages above.\")\n",
    "\n",
    "    print(f\"Successfully loaded {len(samples)} samples\\n\")\n",
    "\n",
    "    df = pd.DataFrame(samples)\n",
    "\n",
    "    return df\n",
    "\n",
    "def resize_image_for_display(image: Image.Image, max_width: int = 600) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Resize image maintaining aspect ratio.\n",
    "\n",
    "    Args:\n",
    "        image: PIL Image object\n",
    "        max_width: Maximum width in pixels\n",
    "\n",
    "    Returns:\n",
    "        Resized PIL Image\n",
    "    \"\"\"\n",
    "    if image.width <= max_width:\n",
    "        return image\n",
    "\n",
    "    aspect_ratio = image.height / image.width\n",
    "    new_height = int(max_width * aspect_ratio)\n",
    "\n",
    "    return image.resize((max_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "df_invoices = load_dataset_from_hf(\n",
    "    dataset_name=\"mychen76/invoices-and-receipts_ocr_v1\",\n",
    "    func_extract=extract_invoice_data,\n",
    "    n_samples=IMAGE_SAMPLE_SIZE\n",
    ")\n",
    "\n",
    "print(f\"DataFrame shape: {df_invoices.shape}\")\n",
    "print(f\"Columns: {df_invoices.columns.tolist()}\")\n",
    "\n",
    "\n",
    "print(f\"\\nFirst row preview:\")\n",
    "print(f\"  Invoice No: {df_invoices.iloc[0]['invoice_no']}\")\n",
    "print(f\"  Invoice Date: {df_invoices.iloc[0]['invoice_date']}\")\n",
    "print(f\"  Number of items: {len(df_invoices.iloc[0]['items'])}\")\n",
    "print(f\"  Summary of purchase: {df_invoices.iloc[0][\"summary\"]} \")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Invoice Example:\")\n",
    "print(\"=\"*80)\n",
    "_first_image = resize_image_for_display(df_invoices.iloc[0]['image'], max_width=600)\n",
    "display(_first_image)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Use pydantic classes to set structured output for invoice data extraction",
   "id": "13e5f87ecefb3852"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class InvoiceItem(BaseModel):\n",
    "    \"\"\"Individual line item on an invoice\"\"\"\n",
    "    description: str = Field(description=\"Description of the item or service\")\n",
    "    quantity: str = Field(description=\"Quantity ordered\")\n",
    "    unit_price: str = Field(description=\"Price per unit\")\n",
    "    net_worth: str = Field(description=\"Total price before tax\")\n",
    "    vat_rate: Optional[str] = Field(default=None, description=\"VAT/tax rate percentage\")\n",
    "    gross_worth: str = Field(description=\"Total price including tax\")\n",
    "\n",
    "class InvoiceData(BaseModel):\n",
    "    \"\"\"Structured invoice data extraction\"\"\"\n",
    "    invoice_no: str = Field(description=\"Invoice number or ID\")\n",
    "    invoice_date: str = Field(description=\"Invoice date in original format\")\n",
    "    items: List[InvoiceItem] = Field(description=\"List of items on the invoice\")\n",
    "    total_gross_worth: str = Field(description=\"Total amount including all taxes\")\n"
   ],
   "id": "10d0ba885c624bf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "INVOICE_PROMPT = \"\"\"\n",
    "        Extract the following information from this invoice with precise formatting:\n",
    "\n",
    "        **Invoice Number**: Extract as plain text/numbers only (e.g., \"27301261\", \"INV-2024-001\")\n",
    "\n",
    "        **Invoice Date**: Extract in MM/DD/YYYY format only (e.g., \"03/15/2024\", \"12/01/2023\")\n",
    "        - If date is in other formats, convert to MM/DD/YYYY\n",
    "        - Use two digits for month and day, four digits for year\n",
    "\n",
    "        **Line Items**: For each item extract:\n",
    "        - Description: Full product/service description as written\n",
    "        - Quantity: Numeric value only as decimal (e.g., 5.00, 2.50, 1.00)\n",
    "          * Remove any text like \"units\", \"pcs\", \"ea\"\n",
    "          * Convert commas to decimals: \"5,00\" becomes \"5.00\"\n",
    "        - Gross Worth: Numeric value only as decimal (e.g., 247.50, 1485.00, 8.25)\n",
    "          * Remove currency symbols ($, €, £)\n",
    "          * Remove spaces and thousands separators\n",
    "          * Use period as decimal separator\n",
    "          * Format: 0.00 (always two decimal places)\n",
    "\n",
    "        **Total Gross Worth**: Final invoice total as numeric decimal only\n",
    "        - Format: 0.00 (e.g., 544.46, 57483.07, 176.00)\n",
    "        - Remove currency symbols, spaces, and separators\n",
    "        - Use period as decimal separator\n",
    "        - Must match sum of all line items\n",
    "\n",
    "        **Critical Rules**:\n",
    "        1. Numbers: Always use period (.) for decimals, never comma (,)\n",
    "        2. Currency: Strip all currency symbols and output numbers only\n",
    "        3. Quantities: Must be valid decimal numbers (e.g., 5.00 not \"5,00\" or \"/gross worth\")\n",
    "        4. Dates: Always MM/DD/YYYY format\n",
    "        5. If a field is unclear or missing, use null/empty rather than placeholder text\n",
    "\n",
    "        **Example Output Format**:\n",
    "        - Invoice Number: \"27301261\"\n",
    "        - Invoice Date: \"10/09/2012\"\n",
    "        - Line Item: Description=\"Product ABC\", Quantity=5.00, Gross Worth=247.50\n",
    "        - Total Gross Worth: 544.46\n",
    "\"\"\"\n",
    "\n",
    "def normalize_currency(value: str) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Normalize currency string to float for comparison.\n",
    "    Handles various formats: $8,25 | 8,25 | $ 544,46 | 57 483,07\n",
    "\n",
    "    Args:\n",
    "        value: Currency string in various formats\n",
    "\n",
    "    Returns:\n",
    "        Float value or None if parsing fails\n",
    "    \"\"\"\n",
    "    if not value:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        cleaned = re.sub(r'[$€£¥\\s{}]', '', str(value))\n",
    "\n",
    "        if ',' in cleaned:\n",
    "            parts = cleaned.split(',')\n",
    "            if len(parts) == 2 and len(parts[1]) == 2:\n",
    "                cleaned = parts[0].replace('.', '').replace(' ', '') + '.' + parts[1]\n",
    "            else:\n",
    "                cleaned = cleaned.replace(',', '')\n",
    "\n",
    "        return float(cleaned)\n",
    "    except (ValueError, AttributeError) as e:\n",
    "        print(f\"Warning: Could not parse currency '{value}': {e}\")\n",
    "        return None\n",
    "\n",
    "def normalize_date(date_str: str) -> Optional[str]:\n",
    "    \"\"\"Normalize various date formats to YYYY-MM-DD\"\"\"\n",
    "    formats = ['%m/%d/%Y', '%Y-%m-%d', '%d/%m/%Y']\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt).strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def compare_invoice_extraction(df: pd.DataFrame, model_name: str = MODEL_NAME) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extract invoice data from all images and compare with ground truth.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with invoice images and ground truth data\n",
    "        model_name: Name of the model being used\n",
    "\n",
    "    Returns:\n",
    "        List of comparison results\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    print(f\"Analyzing {len(df)} invoices with {model_name}...\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(f\"INVOICE {idx + 1}/{len(df)}\")\n",
    "        print(f\"{'='*100}\")\n",
    "\n",
    "        # Extract using model\n",
    "        try:\n",
    "            extracted = analyze_image(\n",
    "                image_source=row['image'],\n",
    "                prompt=INVOICE_PROMPT,\n",
    "                structured_schema=InvoiceData\n",
    "            )\n",
    "\n",
    "            # Ground truth values\n",
    "            gt_invoice_no = row['invoice_no']\n",
    "            gt_date = normalize_date(row['invoice_date'])\n",
    "            gt_total = row['summary']['total_gross_worth']\n",
    "            gt_items = row['items']\n",
    "\n",
    "            # Extracted values\n",
    "            ex_invoice_no = extracted.invoice_no\n",
    "            ex_date = normalize_date(extracted.invoice_date)\n",
    "            ex_total = extracted.total_gross_worth\n",
    "            ex_items = extracted.items\n",
    "\n",
    "            # Normalize currency values for comparison\n",
    "            gt_total_float = normalize_currency(gt_total)\n",
    "            ex_total_float = normalize_currency(ex_total)\n",
    "\n",
    "            # Calculate matches\n",
    "            invoice_match = gt_invoice_no == ex_invoice_no\n",
    "            date_match = gt_date == ex_date\n",
    "\n",
    "            # Compare currency with tolerance for floating point precision\n",
    "            if gt_total_float is not None and ex_total_float is not None:\n",
    "                total_match = abs(gt_total_float - ex_total_float) < 0.01\n",
    "            else:\n",
    "                total_match = False\n",
    "\n",
    "            item_count_match = len(gt_items) == len(ex_items)\n",
    "\n",
    "            # Print comparison\n",
    "            print(f\"\\n{'Field':<20} {'Ground Truth':<25} {'Extracted':<25} {'Match'}\")\n",
    "            print(f\"{'-'*20} {'-'*25} {'-'*25} {'-'*5}\")\n",
    "            print(f\"{'Invoice No':<20} {gt_invoice_no:<25} {ex_invoice_no:<25} {'✓' if invoice_match else '✗'}\")\n",
    "            print(f\"{'Date':<20} {gt_date:<25} {ex_date:<25} {'✓' if date_match else '✗'}\")\n",
    "            print(f\"{'Total (raw)':<20} {gt_total:<25} {ex_total:<25} {'✓' if total_match else '✗'}\")\n",
    "            print(f\"{'Total (float)':<20} {f'{gt_total_float:.2f}' if gt_total_float else 'N/A':<25} {f'{ex_total_float:.2f}' if ex_total_float else 'N/A':<25} {'✓' if total_match else '✗'}\")\n",
    "            print(f\"{'Item Count':<20} {len(gt_items):<25} {len(ex_items):<25} {'✓' if item_count_match else '✗'}\")\n",
    "\n",
    "            # Print item details\n",
    "            print(f\"\\nLine Items:\")\n",
    "            print(f\"  Ground Truth: {len(gt_items)} items\")\n",
    "            for i, item in enumerate(gt_items, 1):\n",
    "                print(f\"    {i}. {item['item_desc'][:60]}... | Qty: {item['item_qty']} | Total: {item['item_gross_worth']}\")\n",
    "\n",
    "            print(f\"\\n  Extracted: {len(ex_items)} items\")\n",
    "            for i, item in enumerate(ex_items, 1):\n",
    "                print(f\"    {i}. {item.description[:60]}... | Qty: {item.quantity} | Total: {item.gross_worth}\")\n",
    "\n",
    "            results.append({\n",
    "                'index': idx,\n",
    "                'invoice_no_match': invoice_match,\n",
    "                'date_match': date_match,\n",
    "                'total_match': total_match,\n",
    "                'item_count_match': item_count_match,\n",
    "                'ground_truth': {\n",
    "                    'invoice_no': gt_invoice_no,\n",
    "                    'date': gt_date,\n",
    "                    'total_raw': gt_total,\n",
    "                    'total_float': gt_total_float,\n",
    "                    'item_count': len(gt_items)\n",
    "                },\n",
    "                'extracted': {\n",
    "                    'invoice_no': ex_invoice_no,\n",
    "                    'date': ex_date,\n",
    "                    'total_raw': ex_total,\n",
    "                    'total_float': ex_total_float,\n",
    "                    'item_count': len(ex_items)\n",
    "                }\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ ERROR: Failed to process invoice {idx + 1}\")\n",
    "            print(f\"   Error: {str(e)}\")\n",
    "            results.append({\n",
    "                'index': idx,\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "    return results\n"
   ],
   "id": "e2ebc44ce209f577",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run comparison\n",
    "comparison_results = compare_invoice_extraction(df_invoices)\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*100}\")\n",
    "\n",
    "successful_results = [r for r in comparison_results if 'error' not in r]\n",
    "if successful_results:\n",
    "    accuracy_df = pd.DataFrame(successful_results)\n",
    "\n",
    "    print(f\"\\nTotal Invoices Processed: {len(df_invoices)}\")\n",
    "    print(f\"Successful Extractions: {len(successful_results)}\")\n",
    "    print(f\"Failed Extractions: {len(comparison_results) - len(successful_results)}\")\n",
    "\n",
    "    print(f\"\\nField Accuracy:\")\n",
    "    print(f\"  Invoice Number: {accuracy_df['invoice_no_match'].mean():.1%}\")\n",
    "    print(f\"  Date:           {accuracy_df['date_match'].mean():.1%}\")\n",
    "    print(f\"  Total Amount:   {accuracy_df['total_match'].mean():.1%}\")\n",
    "    print(f\"  Item Count:     {accuracy_df['item_count_match'].mean():.1%}\")\n",
    "    print(f\"\\nOverall Accuracy: {accuracy_df[['invoice_no_match', 'date_match', 'total_match', 'item_count_match']].mean().mean():.1%}\")"
   ],
   "id": "48351469340df8fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Cleanup: delete deployment to avoid incurring extra costs",
   "id": "c1b2213736fea57a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "! firectl delete deployment -a <YOUR-ACCOUNT-ID> <DEPLOYMENT-ID>",
   "id": "28ed95097346b797"
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated **NVIDIA Nemotron Nano 2 VL** on Fireworks AI for invoice processing and document intelligence.\n",
    "\n",
    "### Architecture Highlights\n",
    "- 12B parameter multimodal model with hybrid transformer-Mamba architecture\n",
    "- Optimized for OCR, document understanding, and video understanding\n",
    "\n",
    "### Invoice Processing Results\n",
    "- **Dataset**: HuggingFace `mychen76/invoices-and-receipts_ocr_v1`\n",
    "- **Task**: Extract invoice numbers, dates, line items, and totals\n",
    "- **Accuracy**:\n",
    "  - Invoice Number: **100%**\n",
    "  - Date: **100%**\n",
    "  - Item Count: **100%**\n",
    "  - Total Amount: **63.2%**\n",
    "  - **Overall: 90.8%** (19/20 successful extractions)\n",
    "\n",
    "### Real-World Applications\n",
    "- Accounts payable automation\n",
    "- Expense management and receipt processing\n",
    "- Financial document digitization\n",
    "- Compliance and audit workflows\n",
    "\n",
    "### Next Steps\n",
    "Ready to deploy in production? Try:\n",
    "- Testing with your domain-specific documents\n",
    "- Adding validation rules for total amount extraction\n",
    "- Implementing confidence-based routing for human review\n",
    "- Scaling to multi-page documents (contracts, statements, purchase orders)\n",
    "\n",
    "Deploy Nemotron Nano 2 VL on Fireworks AI to automate your document intelligence workflows today."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6aee631f57712672"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
