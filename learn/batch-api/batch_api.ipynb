{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fw-ai/cookbook/blob/main/learn/batch-api/batch_api.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Started with Batch API\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The Batch API is designed for asynchronous processing of long-running API tasks by offloading execution and storing results for later retrieval. This architecture is ideal for workloads such as media processing, transcription, translation, and other time-intensive operations that benefit from deferred, non-blocking execution.\n",
    "\n",
    "Key advantages of this Batch API design include:\n",
    "* **Simpler client interaction**: Each request submits a single job without needing to manage complex sessions or bundle multiple files together.\n",
    "* **No HTTP timeout issues**: Background processing ensures large uploads or long-running tasks are reliably handled without connection instability.\n",
    "* **Better retry and fault tolerance**: If one submission fails, the client can simply retry that file without affecting the rest of the batch.\n",
    "* **Greater flexibility**: Clients can adjust submission strategies based on different use cases and application scenarios.\n",
    "\n",
    "> **Design Note:**  \n",
    ">\n",
    "> In typical batch jobs such as audio transcription, audio translation, and other media processing tasks, we often need to handle relatively large files or long-running processing tasks.  To maximize reliability, fault tolerance, and scalability, each file or request is submitted individually to the backend, instead of bundling multiple files together in a single request. The backend system processes each request asynchronously, and assigns a unique batch identifier to each submission for independent tracking and retrieval.  \n",
    ">\n",
    "> This approach improves fault isolation, allows flexible retrying, and ensures the system can robustly handle large-scale workloads.  \n",
    "\n",
    "\n",
    "Clients submit requests synchronously over HTTP, specifying a target **endpoint_id** and **path** that define the backend service and API route. The server then processes these requests asynchronously in the background. Clients can check request status at any time and retrieve results once processing is complete. The system is fully endpoint-agnostic, allowing it to seamlessly route and support a wide range of backend services across Fireworks.AI's infrastructure.\n",
    "\n",
    "For more information on Batch API parameters, including endpoint_id, path, and others, please refer to the link below:\n",
    "\n",
    "- [Create Batch Request – Fireworks Docs](https://docs.fireworks.ai/api-reference/create-batch-request)  \n",
    "- [Check Batch Status – Fireworks Docs](https://docs.fireworks.ai/api-reference/get-batch-status)\n",
    "\n",
    "This notebook gives examples of:\n",
    "\n",
    "*  Submit multiple files from a local directory for asynchronous batch processing;\n",
    "*  Track submissions and their statuses using a CSV file;\n",
    "*  Check the processing status of each submitted request and retrieve results once they are completed;\n",
    "*  Parse the body field of the response based on its content_type to access the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare audio Samples\n",
    "\n",
    "In this example, we'll download multiple pre-recorded audio files into a local directory.\n",
    "These files will be individually submitted to the Batch API for asynchronous transcription processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p audio_samples\n",
    "!curl -L -o \"audio_samples/audio_sample_1.flac\" \"https://tinyurl.com/4997djsh\"\n",
    "!curl -L -o \"audio_samples/audio_sample_2.flac\" \"https://tinyurl.com/4997djsh\"\n",
    "!curl -L -o \"audio_samples/audio_sample_3.flac\" \"https://tinyurl.com/4997djsh\"\n",
    "!curl -L -o \"audio_samples/audio_sample_4.flac\" \"https://tinyurl.com/4997djsh\"\n",
    "!curl -L -o \"audio_samples/audio_sample_5.flac\" \"https://tinyurl.com/4997djsh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up API credentials\n",
    "\n",
    "To use the Fireworks Batch API, you'll need your API key. For security reasons, we'll get it from environment variables.\n",
    "\n",
    "You can set your API key in the notebook by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"FIREWORKS_API_KEY\"] = \"your-api-key-here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submitting a Batch Processing Request\n",
    "\n",
    "This section demonstrates how to submit multiple requests to the Batch API for asynchronous batch processing.\n",
    "\n",
    "Files are loaded from a local directory, and submission results are recorded in a CSV file for later tracking.\n",
    "\n",
    "When constructing your request, you’ll need to specify the following key parameters:\n",
    "\n",
    "* **`endpoint_id`**: Identifies the target backend service or model to handle the request (e.g., `\"audio-prod\"`, `\"audio-turbo\"`). This must be compatible with the selected operation or model type. You can refer to the [official documentation](https://docs.fireworks.ai/api-reference/create-batch-request) for a complete list of supported `endpoint_id`s and their corresponding services.\n",
    "\n",
    "* **`path`**: The relative route of the target API operation (e.g., `\"v1/audio/transcriptions\"`, `\"v1/audio/translations\"`). This should correspond to a valid route supported by the backend service.\n",
    "\n",
    "* **`payload`**: Contains the input data and configuration specific to the selected API route. Its structure should match the schema expected by the corresponding synchronous API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following example demonstrates how to submit multiple files individually to the transcription service for asynchronous batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "\n",
    "\n",
    "# === [Required by User] Define your input ===\n",
    "audio_folder = \"audio_samples\"\n",
    "path = \"v1/audio/transcriptions\"\n",
    "endpoint_id = \"audio-prod\"\n",
    "payload = {\"model\": \"whisper-v3\", \"response_format\": \"json\"}\n",
    "\n",
    "\n",
    "# === [Environment and system settings] ===\n",
    "api_key = os.environ.get(\"FIREWORKS_API_KEY\")\n",
    "batch_url = \"https://batch.us-nevada-1.direct.fireworks.ai/\"\n",
    "url = batch_url + path\n",
    "params = {\"endpoint_id\": endpoint_id}\n",
    "\n",
    "\n",
    "# === [Helper function] Submit a single file ===\n",
    "def submit_single_file(audio_file_path):\n",
    "    headers = {\"Authorization\": api_key}\n",
    "    try:\n",
    "        with open(audio_file_path, \"rb\") as f:\n",
    "            # 'files' must be a dictionary (required by the requests library) even when uploading a single file.\n",
    "            # The number of files supported per request depends on the specific backend API.\n",
    "            files = {\"file\": f}\n",
    "            response = requests.post(url, files=files, data=payload, headers=headers, params=params)\n",
    "\n",
    "        return {\n",
    "            \"audio_file\": os.path.basename(audio_file_path),\n",
    "            \"status_code\": response.status_code,\n",
    "            \"response_json\": response.json(),\n",
    "            \"error\": \"\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"audio_file\": os.path.basename(audio_file_path),\n",
    "            \"status_code\": None,\n",
    "            \"response_json\": None,\n",
    "            \"error\": str(e),\n",
    "        }\n",
    "\n",
    "\n",
    "# === [Batch submit all files] ===\n",
    "def batch_submit_all_files(audio_folder):\n",
    "    audio_files = [os.path.join(audio_folder, f) for f in os.listdir(audio_folder)]\n",
    "\n",
    "    if not audio_files:\n",
    "        print(f\"No audio files found in {audio_folder}\")\n",
    "        return\n",
    "\n",
    "    results = []\n",
    "    for audio_file in audio_files:\n",
    "        res = submit_single_file(audio_file)\n",
    "        results.append(res)\n",
    "\n",
    "        if res[\"status_code\"] is not None and 200 <= res[\"status_code\"] < 300:\n",
    "            account_id = res[\"response_json\"].get(\"account_id\", \"\")\n",
    "            batch_id = res[\"response_json\"].get(\"batch_id\", \"\")\n",
    "            print(f\"Successfully submitted {res['audio_file']}, Account ID: {account_id}, Batch ID: {batch_id}\")\n",
    "        else:\n",
    "            error_message = (\n",
    "                res[\"response_json\"].get(\"error\", \"Unknown error\") if res[\"response_json\"] else res[\"error\"]\n",
    "            )\n",
    "            print(f\"Failed to submit {res['audio_file']}: {error_message}\")\n",
    "    \n",
    "    # === [Write Initial Batch Submission Status to CSV] ===\n",
    "    with open(\"batch_submission_status.csv\", mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(\n",
    "            f, fieldnames=[\"audio_file\", \"status\", \"account_id\", \"batch_id\", \"content_type\", \"response_body\"]\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        for res in results:\n",
    "            if res[\"status_code\"] is not None and 200 <= res[\"status_code\"] < 300:\n",
    "                status = \"processing\"\n",
    "            else:\n",
    "                status = \"failed\"\n",
    "\n",
    "            row = {\n",
    "                \"audio_file\": res[\"audio_file\"],\n",
    "                \"status\": status,\n",
    "                \"account_id\": res[\"response_json\"].get(\"account_id\", \"\"),\n",
    "                \"batch_id\": res[\"response_json\"].get(\"batch_id\", \"\"),\n",
    "                \"content_type\": \"\",\n",
    "                \"response_body\": \"\",\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "batch_submit_all_files(\"audio_samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the submission statuses saved in `batch_submission_status.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat batch_submission_status.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check Batch Processing Status and Retrieve Results\n",
    "\n",
    "After submission, you can check whether each file has completed processing by querying the Batch API using the recorded account_id and batch_id.\n",
    "Completed results are updated back into the CSV file for later parsing.\n",
    "\n",
    "- **`account_id`**: This can be found on your [Fireworks AI account homepage](https://fireworks.ai/account/home), it was also returned in the response when you initially submitted the batch request.\n",
    "\n",
    "- **`batch_id`**: This was returned in the response when you initially submitted the batch request.\n",
    "\n",
    "If the batch job has completed, the response includes a `body` and a `content_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "\n",
    "\n",
    "# === [Environment and system settings] ===\n",
    "api_key = os.environ.get(\"FIREWORKS_API_KEY\")\n",
    "csv_file = \"batch_submission_status.csv\"\n",
    "\n",
    "\n",
    "# === [Helper function] Check a single batch ===\n",
    "def check_single_batch(entry):\n",
    "    account_id = entry.get(\"account_id\")\n",
    "    batch_id = entry.get(\"batch_id\")\n",
    "    audio_file = os.path.splitext(entry.get(\"audio_file\", \"\"))[0]\n",
    "\n",
    "    if not account_id or not batch_id:\n",
    "        return entry, False\n",
    "\n",
    "    url = f\"{batch_url}v1/accounts/{account_id}/batch_job/{batch_id}\"\n",
    "    headers = {\"Authorization\": api_key}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        result = response.json()\n",
    "        status = result.get(\"status\", \"\")\n",
    "        content_type = result.get(\"content_type\", \"\")\n",
    "        body = result.get(\"body\", \"\")\n",
    "\n",
    "        print(f\"Audio File: {audio_file}, Batch ID: {batch_id}, Status: {status}\")\n",
    "\n",
    "        if status == \"completed\":\n",
    "            entry[\"status\"] = \"completed\"\n",
    "            entry[\"content_type\"] = content_type\n",
    "            entry[\"response_body\"] = body\n",
    "            return entry, True\n",
    "\n",
    "        return entry, False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Request failed for {audio_file}: {e}\")\n",
    "        return entry, False\n",
    "\n",
    "\n",
    "# === [Check Processing Batches and Save Status Updates] ===\n",
    "try:\n",
    "    # Wait for the backend to finish processing before checking status\n",
    "    time.sleep(10)\n",
    "\n",
    "    with open(csv_file, mode=\"r\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        entries = list(reader)\n",
    "\n",
    "    if not entries:\n",
    "        print(\"No entries to process.\")\n",
    "    else:\n",
    "        # Filter entries to only process those with status \"processing\"\n",
    "        processing_row_indices = [i for i, entry in enumerate(entries) if entry[\"status\"] == \"processing\"]\n",
    "\n",
    "        for idx in processing_row_indices:\n",
    "            updated_entry, _ = check_single_batch(entries[idx])\n",
    "            entries[idx] = updated_entry\n",
    "\n",
    "    # Rewrite CSV: update all entries\n",
    "    with open(csv_file, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(\n",
    "            f, fieldnames=[\"audio_file\", \"status\", \"account_id\", \"batch_id\", \"content_type\", \"response_body\"]\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        writer.writerows(entries)\n",
    "\n",
    "    print(\"Batch job statuses updated.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the updated submission statuses saved in `batch_submission_status.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat batch_submission_status.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parse and Display Completed Batch Responses\n",
    "\n",
    "After the batch jobs have completed, you can parse the `body` field of each completed entry based on its `content_type`.\n",
    "\n",
    "Parse the body according to its `content_type`, such as `application/json` for structured data (e.g., `json`, `verbose_json`), or `text/plain; charset=utf-8` for plain text formats (e.g., `text`, `srt`, `vtt`), to reconstruct the original response from the backend service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from email.parser import Parser\n",
    "\n",
    "csv_file = \"batch_submission_status.csv\"\n",
    "\n",
    "# === [Parse and Display Responses for Completed Batch Jobs] ===\n",
    "with open(csv_file, mode=\"r\", newline=\"\") as f:\n",
    "    entries = list(csv.DictReader(f))\n",
    "\n",
    "for idx, entry in enumerate(entries):\n",
    "    if entry.get(\"status\") != \"completed\":\n",
    "        continue\n",
    "\n",
    "    audio_file = entry.get(\"audio_file\", \"\")\n",
    "    content_type = entry.get(\"content_type\", \"\")\n",
    "    body = entry.get(\"response_body\", \"\")\n",
    "\n",
    "    print(f\"[{idx}] Audio File: {audio_file}\")\n",
    "\n",
    "    # Parse content_type\n",
    "    main_type = Parser().parsestr(f\"Content-Type: {content_type}\").get_content_type()\n",
    "\n",
    "    # Parse and print body based on content_type\n",
    "    if main_type == \"application/json\":\n",
    "        try:\n",
    "            parsed = json.loads(body)\n",
    "            print(json.dumps(parsed, indent=2))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse JSON: {e}\")\n",
    "            print(body)\n",
    "    elif main_type == \"text/plain\":\n",
    "        print(body)\n",
    "    else:\n",
    "        print(\"Unsupported Content-Type. Raw body:\")\n",
    "        print(body)\n",
    "\n",
    "print(\"Done parsing completed entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, you learned how to use the Fireworks.AI Batch API to asynchronously process long-running requests by submitting multiple files individually.\n",
    "\n",
    "We covered how to prepare files from a local directory, submit each file as a separate batch request, track submission statuses in a CSV file, check processing status, retrieve results once completed, and parse the response body based on its content type.\n",
    "\n",
    "This approach is especially useful for workloads such as transcription, translation, and other media-related tasks that benefit from asynchronous, scalable processing.\n",
    "\n",
    "For more information, see:\n",
    "\n",
    "- [Create Batch Request – Fireworks Docs](https://docs.fireworks.ai/api-reference/create-batch-request)  \n",
    "- [Check Batch Status – Fireworks Docs](https://docs.fireworks.ai/api-reference/get-batch-status)\n",
    "\n",
    "Explore the community or reach out to us in [discord](https://discord.gg/fireworks-ai)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
