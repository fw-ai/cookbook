{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent example for Fireworks + MongoDB + Nomic embedding model\n",
    "\n",
    "## Introduction\n",
    "We just went through the Fireworks tutorial for MongoDB and nomic embedding, with all the data indexed. Now we are going to dig into using how to use an agent framework to drive the interaction, since you may not want to just use embedding to do the work sometimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Your Environment\n",
    "Before we dive into the code, make sure to set up your environment. This involves installing necessary packages like pymongo and openai. Run the following command in your notebook to install these packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (4.6.1)\n",
      "Requirement already satisfied: openai in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (1.9.0)\n",
      "Requirement already satisfied: tqdm in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (4.66.1)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.8-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.0.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.14-py3-none-any.whl.metadata (478 bytes)\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from pymongo) (2.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from langchain) (0.6.3)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.21 (from langchain)\n",
      "  Downloading langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.24 (from langchain)\n",
      "  Downloading langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain)\n",
      "  Downloading langsmith-0.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Collecting openai\n",
      "  Downloading openai-1.12.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from langchain_openai) (0.5.2)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.31.0.20240218-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: certifi in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.24->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/bchen/cookbook/.venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.1.8-py3-none-any.whl (816 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.1/816.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.0.6-py3-none-any.whl (29 kB)\n",
      "Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchainhub-0.1.14-py3-none-any.whl (3.4 kB)\n",
      "Downloading numexpr-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (375 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.2/375.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.21-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.25-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.1.5-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.31.0.20240218-py3-none-any.whl (14 kB)\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Installing collected packages: types-requests, numexpr, jsonpointer, langchainhub, jsonpatch, openai, langsmith, langchain-core, langchain_openai, langchain-community, langchain\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.9.0\n",
      "    Uninstalling openai-1.9.0:\n",
      "      Successfully uninstalled openai-1.9.0\n",
      "Successfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.8 langchain-community-0.0.21 langchain-core-0.1.25 langchain_openai-0.0.6 langchainhub-0.1.14 langsmith-0.1.5 numexpr-2.9.0 openai-1.12.0 types-requests-2.31.0.20240218\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo openai tqdm langchain openai langchain_openai langchainhub numexpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Fireworks and MongoDB Clients\n",
    "To interact with Fireworks and MongoDB, we need to initialize their respective clients. Replace \"YOUR FIREWORKS API KEY\" and \"YOUR MONGO URL\" with your actual credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pymongo\n",
    "\n",
    "mongo_url = input()\n",
    "client = pymongo.MongoClient(mongo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_api_key = input()\n",
    "fw_client = openai.OpenAI(\n",
    "  api_key=fw_api_key,\n",
    "  base_url=\"https://api.fireworks.ai/inference/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking an agent framework you prefer\n",
    "There are many agent frameworks on the market for you to choose from. We will use LangChain as the tool to drive MongoDB integration here. There are a few steps we need to take here\n",
    "- A tool that fetches the MongoDB schema, so our function calling model can know what field to filter on\n",
    "- A tool that fetches embeddings given the user query\n",
    "- A tool that executes MongoDB queries, with both the filter and the vector embeddings\n",
    "\n",
    "We will first begin with basic LangChain tool setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain import hub\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from typing import Optional, Type\n",
    "from langchain.globals import set_debug\n",
    "from langchain.globals import set_verbose\n",
    "\n",
    "\n",
    "set_debug(True)\n",
    "set_verbose(True)\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.fireworks.ai/inference/v1\",\n",
    "    api_key=fw_api_key,\n",
    "    model=\"accounts/fireworks/models/firefunction-v1\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=256,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "class FetchSchemaInput(BaseModel):\n",
    "    db: str = Field(description=\"name of the database\")\n",
    "    collection: str = Field(description=\"name of the collection\")\n",
    "\n",
    "class FetchSchemaTool(BaseTool):\n",
    "    name: str = \"FetchSchemaTool\"\n",
    "    description: str = \"Get the schema for the corresponding db and collection\"\n",
    "    args_schema: Type[BaseModel] = FetchSchemaInput\n",
    "\n",
    "    def _run(self, db: str, collection: str) -> Dict[str, Any]:\n",
    "        \"\"\"Fetch the schema from the specified db and collection\n",
    "\n",
    "        Args:\n",
    "            db: name of the mongodb database\n",
    "            collection: name of the mongodb collection\n",
    "        \"\"\"\n",
    "        return dict([(x, type(y)) for x, y in client[db][collection].find_one().items()])\n",
    "\n",
    "class MongoDBAtlasSearchInput(BaseModel):\n",
    "    user_query: str = Field(description=\"faith representation of user query to generate the embeddings from\")\n",
    "    db: str = Field(description=\"name of the database\")\n",
    "    collection: str = Field(description=\"name of the collection\")\n",
    "    filter: Dict[str, Any] = Field(description=\"mongodb filter for the given query\")\n",
    "\n",
    "class MongoDBAtlasSearchTool(BaseTool):\n",
    "    name: str = \"MongoDBAtlasSearchTool\"\n",
    "    description: str = \"Look up into MongoDB Altas based on filters and embeddings\"\n",
    "    args_schema: Type[BaseModel] = MongoDBAtlasSearchInput\n",
    "\n",
    "    def _run(self, user_query: str, db: str, collection: str, filter: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Fetch the schema from the specified db and collection\n",
    "        \"\"\"\n",
    "        embedding = [x.embedding for x in \n",
    "            fw_client.embeddings.create(\n",
    "            input=[user_query],\n",
    "            model=\"nomic-ai/nomic-embed-text-v1.5\"\n",
    "        ).data][0]\n",
    "        return {doc['title'] for doc in client[db][collection].aggregate([{\n",
    "            # vector search fields are hard coded right now to make things cleaner, but we can also inject into\n",
    "            # the system prompt and let the model handle it\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"movie_index\",\n",
    "                \"path\": \"embedding_2k_movies_fw_nomic_1_5\",\n",
    "                \"queryVector\": embedding,\n",
    "                \"numCandidates\": 100,\n",
    "                \"limit\": 10,\n",
    "                \"filter\": filter\n",
    "            }\n",
    "        }])}\n",
    "\n",
    "tools = [\n",
    "  FetchSchemaTool(),\n",
    "  MongoDBAtlasSearchTool(),\n",
    "]\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an expert MongoDB user that turns user query into model requests.\n",
    "Whenever you are faced with a user query, you should first fetch the mongoDB schema for database \"sample_mflix\" and collection \"movies\".\n",
    "Then, you respond to the original user query by looking into MongoDB Atlas\n",
    "- with filter that best match the user query given the schema. The filters will be constructed from the schema you fetched earlier.\n",
    "- as well as the embeddings.\n",
    "After getting the result from MongoDB Atlas, only then respond with your movies recommendations given the fetch results. Do not prematurely respond with any movies recommendations.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "agent = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `FetchSchemaTool` with `{'db': 'sample_mflix', 'collection': 'movies'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'_id': <class 'bson.objectid.ObjectId'>, 'plot': <class 'str'>, 'genres': <class 'list'>, 'runtime': <class 'int'>, 'cast': <class 'list'>, 'num_mflix_comments': <class 'int'>, 'poster': <class 'str'>, 'title': <class 'str'>, 'fullplot': <class 'str'>, 'languages': <class 'list'>, 'released': <class 'datetime.datetime'>, 'directors': <class 'list'>, 'writers': <class 'list'>, 'awards': <class 'dict'>, 'lastupdated': <class 'str'>, 'year': <class 'int'>, 'imdb': <class 'dict'>, 'countries': <class 'list'>, 'type': <class 'str'>, 'tomatoes': <class 'dict'>, 'embedding_2k_movies_fw_e5_mistral': <class 'list'>}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `MongoDBAtlasSearchTool` with `{'user_query': 'spiderman', 'db': 'sample_mflix', 'collection': 'movies', 'filter': {'year': {'$gte': 2000}}}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{'X-Men', 'Fantastic Four', 'Along Came a Spider', 'Gladiator', 'Mission: Impossible II', 'Spider-Man', 'Spooky House', \"Charlie's Angels\", 'Hollow Man', 'Titan A.E.'}\u001b[0m\u001b[32;1m\u001b[1;3mBased on your preference for Spiderman, I recommend the following movies released after 2000: X-Men, Fantastic Four, Along Came a Spider, Gladiator, Mission: Impossible II, Spider-Man, Spooky House, Charlie's Angels, Hollow Man, and Titan A.E.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'I like spiderman, any similar movies you can recommend after the 2000s?', 'output': \"Based on your preference for Spiderman, I recommend the following movies released after 2000: X-Men, Fantastic Four, Along Came a Spider, Gladiator, Mission: Impossible II, Spider-Man, Spooky House, Charlie's Angels, Hollow Man, and Titan A.E.\"}\n"
     ]
    }
   ],
   "source": [
    "print(agent.invoke({\"input\": \"I like spiderman, any similar movies you can recommend after the 2000s?\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
