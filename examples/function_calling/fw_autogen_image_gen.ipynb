{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fw-ai/cookbook/blob/main/examples/function_calling/fw_autogen_image_gen.ipynb)"
      ],
      "metadata": {
        "id": "le6hjy5YGA7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preable - Install Deps\n",
        "\n",
        "There are only a few dependencies for this tutorial."
      ],
      "metadata": {
        "id": "OGGLSlI9C80P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5MKzf6_tFAG"
      },
      "outputs": [],
      "source": [
        "!pip install pyautogen openai fireworks-ai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction - Art Generator\n",
        "\n",
        "In this example we will use AutoGen framework to construct an agent that is capable of generating an image through DALLE-3 and saving it to local disk.\n",
        "\n",
        "For this demo, we are going to utilize [function calling](https://readme.fireworks.ai/docs/function-calling) feature launched by Fireworks. We initialize two agents - `UserProxyAgent` and `AssistantAgent`. The `AssistantAgent` is given the ability to issue a call for the provided functions but not execute them while `UserProxyAgent` is given the ability to execute the function calls issues by the `AssistantAgent`. In order to achieve this behaviour we use decorators provided by AutoGen library called `register_for_llm` and `register_for_execution`. Using these decorators allows us to easily define python functions and turn them into [JSON Spec](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat) needed by function calling API.\n",
        "\n",
        "Finally, we setup system prompt for both the agents. We ask the `AssistantAgent` to be a helpful agent & focus on generating the correct function calls and we leave `UserProxyAgent` as is. For more advanced use cases we can ask `UserProxyAgent` to be a plan generator.\n"
      ],
      "metadata": {
        "id": "34MJ8aTW9ys1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zAuynYvM2c3w"
      },
      "outputs": [],
      "source": [
        "import autogen\n",
        "import asyncio\n",
        "import os\n",
        "from IPython import get_ipython\n",
        "from typing_extensions import Annotated\n",
        "from typing import List\n",
        "import uuid\n",
        "import requests  # to perform HTTP requests\n",
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import fireworks.client\n",
        "from fireworks.client.image import ImageInference, Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "In order to use the Fireworks AI function calling model, you must first obtain Fireworks API Keys. If you don't already have one, you can one by following the instructions [here](https://readme.fireworks.ai/docs/quickstart). Replace FW_API_KEY with your obtained key."
      ],
      "metadata": {
        "id": "ddA-KVZdMoN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FD9w-Ztt3Ssm"
      },
      "outputs": [],
      "source": [
        "FW_API_KEY = \"YOUR_API_KEY\"\n",
        "\n",
        "config_list = [\n",
        "  {\n",
        "    \"model\": \"accounts/fireworks/models/firefunction-v1\",\n",
        "    \"api_key\": FW_API_KEY,\n",
        "    \"base_url\": \"https://api.fireworks.ai/inference/v1\",\n",
        "    \"temperature\": 0.0\n",
        "  }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure Tools\n",
        "\n",
        "For this notebook, we are going to use 2 sets of tools\n",
        "1. **Image Generation** - We will use [StableDiffusion XL](https://fireworks.ai/models/fireworks/stable-diffusion-xl-1024-v1-0) model on Fireworks platform to generate images for us given the prompt. The tool itself would save the file to a randomly generated file name.\n",
        "2. **Show Image** - This tool, given a valid file path, will display the image.\n",
        "\n",
        "\n",
        "Using the AutoGen framework we demonstrate the co-operative nature of agents working with each other to accomplish a complex task. This tutorial can be extended to perform more complicated tasks such as generating stock price charts etc."
      ],
      "metadata": {
        "id": "ZX3i43aUOBUf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5G_iwAz_-NvY"
      },
      "outputs": [],
      "source": [
        "llm_config = {\n",
        "    \"config_list\": config_list,\n",
        "    \"timeout\": 120,\n",
        "    \"temperature\": 0\n",
        "}\n",
        "chatbot = autogen.AssistantAgent(\n",
        "    name=\"chatbot\",\n",
        "    system_message=\"You are a helpful assistant that can use available functions when needed to solve problems. At each point, do your best to determine if the user's request has been addressed. If the request HAS been addressed, respond with a summary of the result. The summary must be written as a coherent helpful response to the user request e.g. 'Sure, here is result to your request ' or 'The tallest mountain in Africa is ..' etc. The summary MUST end with the word TERMINATE. If the  user request is pleasantry or greeting, you should respond with a pleasantry or greeting and TERMINATE.\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "\n",
        "# create a UserProxyAgent instance named \"user_proxy\"\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"user_proxy\",\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE.\"),\n",
        "    human_input_mode=\"NEVER\",\n",
        "    max_consecutive_auto_reply=10,\n",
        "    code_execution_config={\"work_dir\": \"coding\"},\n",
        ")\n",
        "\n",
        "\n",
        "@user_proxy.register_for_execution()\n",
        "@chatbot.register_for_llm(name=\"generate_and_save_images\", description=\"Function to paint, draw or illustrate images based on the users query or request. Generates images from a given query using OpenAI's DALL-E model and saves them to disk. Use the code below anytime there is a request to create an image.\")\n",
        "async def generate_and_save_images(query: Annotated[str, \"A natural language description of the image to be generated\"], image_size: Annotated[str, \"The size of the image to be generated. (default is '1024x1024')\"] = \"1024x1024\") -> List[str]:\n",
        "    \"\"\"\n",
        "    :param query: A natural language description of the image to be generated.\n",
        "    :param image_size: )\n",
        "    :return: A list of filenames for the saved images.\n",
        "    \"\"\"\n",
        "    fireworks.client.api_key = FW_API_KEY\n",
        "    inference_client = ImageInference(model=\"stable-diffusion-xl-1024-v1-0\")\n",
        "\n",
        "    # List to store the file names of saved images\n",
        "    saved_files = []\n",
        "\n",
        "\n",
        "    file_name = str(uuid.uuid4()) + \".jpg\"  # Assuming the image is a JPG\n",
        "    file_path = Path(file_name)\n",
        "\n",
        "    # Generate an image using the text_to_image method\n",
        "    answer : Answer = await inference_client.text_to_image_async(\n",
        "        prompt=query,\n",
        "        cfg_scale=7,\n",
        "        height=1024,\n",
        "        width=1024,\n",
        "        sampler=None,\n",
        "        steps=30,\n",
        "        seed=0,\n",
        "        safety_check=False,\n",
        "        output_image_format=\"JPG\",\n",
        "        # Add additional parameters here as necessary\n",
        "    )\n",
        "\n",
        "    if answer.image is None:\n",
        "      raise RuntimeError(f\"No return image, {answer.finish_reason}\")\n",
        "    else:\n",
        "      answer.image.save(file_path)\n",
        "      print(f\"Image saved to {file_path}\")\n",
        "      saved_files.append(str(file_path))\n",
        "\n",
        "    # Return the list of saved files\n",
        "    return {\"path\": saved_files[0]}\n",
        "\n",
        "# Example usage of the function:\n",
        "# generate_and_save_images(\"A cute baby sea otter\")\n",
        "\n",
        "@user_proxy.register_for_execution()\n",
        "@chatbot.register_for_llm(name=\"show_image\", description=\"A function that is capable for displaying an image given path to a image file in png or jpg or jpeg.\")\n",
        "def show_image(path: Annotated[str, \"The path to the image file that needs to be displayed\"]) -> str:\n",
        "  img = cv2.imread(path,-1)\n",
        "  plt.imshow(img)\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n",
        "  return \"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initiating Chat\n",
        "\n",
        "Now we will use the `initiate_chat` functionality to give our AutoGen bot a complex task to accomplish. For this particular task - we ask it to paint an image of ethiopian coffee and show it's image."
      ],
      "metadata": {
        "id": "lLBZp9LTSYDl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "11CtFkFWNv_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ff7dff-8524-4f0b-cc8b-ac09d538ebc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_proxy (to chatbot):\n",
            "\n",
            "paint and show an image of a glass of ethiopian coffee, freshly brewed in a tall glass cup, on a table right in front of a lush green forest scenery.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "chatbot (to user_proxy):\n",
            "\n",
            " \n",
            "***** Suggested tool Call (call_F18NYriOOks268hACJ1inp9V): generate_and_save_images *****\n",
            "Arguments: \n",
            "{\"query\": \"a glass of ethiopian coffee, freshly brewed in a tall glass cup, on a table right in front of a lush green forest scenery\", \"image_size\": \"1024x1024\"}\n",
            "*****************************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING ASYNC FUNCTION generate_and_save_images...\n",
            "Image saved to aace2257-dd6f-45bb-83dd-75c4fe0cf4c7.jpg\n",
            "user_proxy (to chatbot):\n",
            "\n",
            "user_proxy (to chatbot):\n",
            "\n",
            "***** Response from calling tool \"call_F18NYriOOks268hACJ1inp9V\" *****\n",
            "{\"path\": \"aace2257-dd6f-45bb-83dd-75c4fe0cf4c7.jpg\"}\n",
            "**********************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "chatbot (to user_proxy):\n",
            "\n",
            " Sure, here is the result of your request. I have generated an image of a glass of Ethiopian coffee, freshly brewed in a tall glass cup, on a table right in front of a lush green forest scenery. \n",
            "\n",
            "![Ethiopian Coffee](aace2257-dd6f-45bb-83dd-75c4fe0cf4c7.jpg)\n",
            "\n",
            "TERMINATE.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_history=[{'content': 'paint and show an image of a glass of ethiopian coffee, freshly brewed in a tall glass cup, on a table right in front of a lush green forest scenery.', 'role': 'assistant'}, {'content': ' ', 'tool_calls': [{'id': 'call_F18NYriOOks268hACJ1inp9V', 'function': {'arguments': '{\"query\": \"a glass of ethiopian coffee, freshly brewed in a tall glass cup, on a table right in front of a lush green forest scenery\", \"image_size\": \"1024x1024\"}', 'name': 'generate_and_save_images'}, 'type': 'function', 'index': 0}], 'role': 'assistant'}, {'content': '{\"path\": \"aace2257-dd6f-45bb-83dd-75c4fe0cf4c7.jpg\"}', 'tool_responses': [{'tool_call_id': 'call_F18NYriOOks268hACJ1inp9V', 'role': 'tool', 'content': '{\"path\": \"aace2257-dd6f-45bb-83dd-75c4fe0cf4c7.jpg\"}'}], 'role': 'tool'}, {'content': ' Sure, here is the result of your request. I have generated an image of a glass of Ethiopian coffee, freshly brewed in a tall glass cup, on a table right in front of a lush green forest scenery. \\n\\n![Ethiopian Coffee](aace2257-dd6f-45bb-83dd-75c4fe0cf4c7.jpg)\\n\\nTERMINATE.', 'role': 'user'}], summary='', cost=({'total_cost': 0, 'accounts/fireworks/models/firefunction-v1': {'cost': 0, 'prompt_tokens': 1161, 'completion_tokens': 174, 'total_tokens': 1335}}, {'total_cost': 0, 'accounts/fireworks/models/firefunction-v1': {'cost': 0, 'prompt_tokens': 606, 'completion_tokens': 101, 'total_tokens': 707}}), human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# start the conversation\n",
        "await user_proxy.a_initiate_chat(\n",
        "    chatbot,\n",
        "    message=\"paint and show an image of a glass of ethiopian coffee, freshly brewed in a tall glass cup, on a table right in front of a lush green forest scenery.\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}