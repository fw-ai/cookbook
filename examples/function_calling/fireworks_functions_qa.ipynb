{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fw-ai/cookbook/blob/main/examples/function_calling/fireworks_functions_qa.ipynb)"
      ],
      "metadata": {
        "id": "f5OOOJoXB-O3"
      },
      "id": "f5OOOJoXB-O3"
    },
    {
      "cell_type": "markdown",
      "id": "71a43144",
      "metadata": {
        "id": "71a43144"
      },
      "source": [
        "# Structure answers with Fireworks functions\n",
        "\n",
        "Fireworks (FW) function calling model allows has the ability to produced structured responses. This is often useful in question answering when you want to not only get the final answer but also supporting evidence, citation, etc.\n",
        "\n",
        "In this notebook we show how to use an LLM chain which uses FW functions as part of an overall retrieval pipeline."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "h2cmLE1ACL17"
      },
      "id": "h2cmLE1ACL17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f059012e",
      "metadata": {
        "id": "f059012e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import re\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/hwchase17/chat-your-data/master/state_of_the_union.txt\"\n",
        "content = requests.get(url).content\n",
        "content = str(content, \"utf-8\")"
      ],
      "metadata": {
        "id": "IcIybYoE35ro"
      },
      "id": "IcIybYoE35ro",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some clean up\n",
        "clean_content = content.replace(\"\\n\\n\", \"\\n\")"
      ],
      "metadata": {
        "id": "xTeisbO_4UI7"
      },
      "id": "xTeisbO_4UI7",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI(\n",
        "    base_url = \"https://api.fireworks.ai/inference/v1\",\n",
        "    api_key = \"YOUR_FW_API_KEY\",\n",
        ")\n",
        "model_name = \"accounts/fireworks/models/fw-function-call-34b-v0\""
      ],
      "metadata": {
        "id": "ZlTFlhtB5baq"
      },
      "id": "ZlTFlhtB5baq",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_answer_with_sources\",\n",
        "            \"description\": \"Answer questions from the user while quoting sources.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                  \"answer\": {\n",
        "                      \"type\": \"string\",\n",
        "                      \"description\": \"Answer to the question that was asked.\"\n",
        "                  },\n",
        "                  \"sources\": {\n",
        "                      \"type\": \"array\",\n",
        "                      \"items\": {\n",
        "                          \"type\": \"string\",\n",
        "                          \"description\": \"Source used to answer the question\"\n",
        "                      }\n",
        "                  }\n",
        "                },\n",
        "                \"required\": [\"answer\", \"sources\"],\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "tool_choice = {\"type\": \"function\", \"function\": {\"name\":\"get_answer_with_sources\"}}"
      ],
      "metadata": {
        "id": "Zj-9l4m283b4"
      },
      "id": "Zj-9l4m283b4",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": f\"You are a helpful assistant who is given document with following content: {clean_content}.\"\n",
        "     \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\"Please reply in succinct manner and be truthful in the reply.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What did the president say about Ketanji Brown Jackson?\"}\n",
        "]\n"
      ],
      "metadata": {
        "id": "LcnDoz7H8jjE"
      },
      "id": "LcnDoz7H8jjE",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=tool_choice,\n",
        "    temperature=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "ENX3Fgcd_JfZ"
      },
      "id": "ENX3Fgcd_JfZ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_completion.choices[0].message.model_dump_json(indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WzRJ5PgFAXc",
        "outputId": "ee5a8472-167e-4167-f716-94378d8bd333"
      },
      "id": "0WzRJ5PgFAXc",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"content\": \" \",\n",
            "    \"role\": \"assistant\",\n",
            "    \"function_call\": null,\n",
            "    \"tool_calls\": [\n",
            "        {\n",
            "            \"id\": \"call_fN2C7m2xaRrkZj0O9gV46eKb\",\n",
            "            \"function\": {\n",
            "                \"arguments\": \"{\\\"answer\\\": \\\"I recently nominated Ketanji Brown Jackson to serve on the United States Supreme Court. She is an outstanding candidate and I am confident that she will serve with distinction.\\\", \\\"sources\\\": [\\\"The White House\\\"]}\",\n",
            "                \"name\": \"get_answer_with_sources\"\n",
            "            },\n",
            "            \"type\": \"function\",\n",
            "            \"index\": 0\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_response = chat_completion.choices[0].message\n",
        "\n",
        "messages.append(\n",
        "    {\n",
        "        \"role\": agent_response.role,\n",
        "        \"content\": \"\",\n",
        "        \"tool_calls\": [\n",
        "            tool_call.model_dump()\n",
        "            for tool_call in agent_response.tool_calls\n",
        "        ]\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "bF-o87oxD05g"
      },
      "id": "bF-o87oxD05g",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Function Calling in Conversation\n",
        "\n",
        "Our model currently support multi-turn conversation when using function calling. You can reference previous completions generated by the model to ask more clarifying questions."
      ],
      "metadata": {
        "id": "oC2FSQjDAyL8"
      },
      "id": "oC2FSQjDAyL8"
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append(\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What did he say about her predecessor?\"\n",
        "    }\n",
        ")\n",
        "next_chat_completion = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=tool_choice,\n",
        "    temperature=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "wYGPiSXfAysM"
      },
      "id": "wYGPiSXfAysM",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(next_chat_completion.choices[0].message.model_dump_json(indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkWhQ4hPFMc_",
        "outputId": "dcce465f-8d89-4937-f17c-4906dc142dcd"
      },
      "id": "UkWhQ4hPFMc_",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"content\": null,\n",
            "    \"role\": \"assistant\",\n",
            "    \"function_call\": null,\n",
            "    \"tool_calls\": [\n",
            "        {\n",
            "            \"id\": \"call_SJsaq3GUUK2ugOVlJ025flwH\",\n",
            "            \"function\": {\n",
            "                \"arguments\": \"{\\\"answer\\\": \\\"I am deeply saddened by the passing of Justice Breyer. He was a brilliant jurist and a true American hero. His legacy will live on in the work he did on the Supreme Court and in the lives he touched.\\\", \\\"sources\\\": [\\\"The White House\\\"]}\",\n",
            "                \"name\": \"get_answer_with_sources\"\n",
            "            },\n",
            "            \"type\": \"function\",\n",
            "            \"index\": 0\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifying the output format to more specific one\n",
        "\n",
        "During the conversation, some questions might need a more flexible response format. We have flexibility to change that during the conversation.\n",
        "\n"
      ],
      "metadata": {
        "id": "EU_U5Bm9GJNa"
      },
      "id": "EU_U5Bm9GJNa"
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_answer_with_countries\",\n",
        "            \"description\": \"Answer questions from the user while quoting sources.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                  \"answer\": {\n",
        "                      \"type\": \"string\",\n",
        "                      \"description\": \"Answer to the question that was asked.\"\n",
        "                  },\n",
        "                  \"countries\": {\n",
        "                      \"type\": \"array\",\n",
        "                      \"items\": {\n",
        "                          \"type\": \"string\",\n",
        "                      },\n",
        "                      \"description\": \"countries mentioned in the sources\"\n",
        "                  }\n",
        "                },\n",
        "                \"required\": [\"answer\", \"countries\"],\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "tool_choice = {\"type\": \"function\", \"function\": {\"name\":\"get_answer_with_countries\"}}"
      ],
      "metadata": {
        "id": "JxsGWpUcIGan"
      },
      "id": "JxsGWpUcIGan",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_response = next_chat_completion.choices[0].message\n",
        "\n",
        "messages.append(\n",
        "    {\n",
        "        \"role\": agent_response.role,\n",
        "        \"content\": \"\",\n",
        "        \"tool_calls\": [\n",
        "            tool_call.model_dump()\n",
        "            for tool_call in agent_response.tool_calls\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "\n",
        "messages.append(\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What did he say about human traffickers?\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "g-CYqzXIIUIl"
      },
      "id": "g-CYqzXIIUIl",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=tool_choice,\n",
        "    temperature=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "RylJZ8BiIewx"
      },
      "id": "RylJZ8BiIewx",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_completion.choices[0].message.model_dump_json(indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi_gNf-qI-CG",
        "outputId": "d3018c86-21dd-4b40-9a38-7f14bbec05cd"
      },
      "id": "qi_gNf-qI-CG",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"content\": null,\n",
            "    \"role\": \"assistant\",\n",
            "    \"function_call\": null,\n",
            "    \"tool_calls\": [\n",
            "        {\n",
            "            \"id\": \"call_0Qymk6ZFNVsdjXmOOsmMsYLW\",\n",
            "            \"function\": {\n",
            "                \"arguments\": \"{\\\"answer\\\": \\\"We are working with our partners in South and Central America to host more refugees and secure their own borders. This will help us crack down on human traffickers and reduce the flow of illegal immigrants into the United States.\\\", \\\"countries\\\": [\\\"South America\\\", \\\"Central America\\\"]}\",\n",
            "                \"name\": \"get_answer_with_countries\"\n",
            "            },\n",
            "            \"type\": \"function\",\n",
            "            \"index\": 0\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s9RBCjDHKr2Z"
      },
      "id": "s9RBCjDHKr2Z",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
