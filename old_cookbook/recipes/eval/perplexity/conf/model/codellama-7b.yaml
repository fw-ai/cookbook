defaults:
  - ../../../../common/conf/model/codellama-7b@_here_

name: codellama-7b

flash_attention: True
torch_dtype: bfloat16

# rope_scaling:
#   type: linear
#   factor: 2.0
