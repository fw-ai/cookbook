defaults:
  - ../../../../common/conf/model/codellama-13b-instruct@_here_

name: codellama-13b-instruct-gud

micro_batch_size: 2
batch_size: 16

lr_scheduler_type: cosine

epochs: 5
learning_rate: 3.e-4
cutoff_len: 4096
lora_r: 16
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules:
  - gate_proj
  - down_proj
  - up_proj

gradient_checkpointing: False
flash_attention: True

load_in_4bit: False
torch_dtype: bfloat16
bf16: True
